{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import collections\n",
    "import datetime\n",
    "\n",
    "###print\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###torch import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "from  torch.optim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pandas_reduce_mem_usage\n",
    "def pandas_reduce_mem_usage(df,igore_columns=[]):\n",
    "    start_mem=df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    starttime = datetime.datetime.now()\n",
    "    for col in df.columns:\n",
    "        if col in igore_columns:\n",
    "            continue\n",
    "        col_type=df[col].dtype   #每一列的类型\n",
    "        if col_type !=object:    #不是object类型\n",
    "            c_min=df[col].min()\n",
    "            c_max=df[col].max()\n",
    "            # print('{} column dtype is {} and begin convert to others'.format(col,col_type))\n",
    "            if str(col_type)[:3]=='int':\n",
    "                #是有符号整数\n",
    "                if c_min<0:\n",
    "                    if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min >= np.iinfo(np.uint8).min and c_max<=np.iinfo(np.uint8).max:\n",
    "                        df[col]=df[col].astype(np.uint8)\n",
    "                    elif c_min >= np.iinfo(np.uint16).min and c_max <= np.iinfo(np.uint16).max:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_min >= np.iinfo(np.uint32).min and c_max <= np.iinfo(np.uint32).max:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "            #浮点数\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "            # print('\\t\\tcolumn dtype is {}'.format(df[col].dtype))\n",
    "\n",
    "        #是object类型，比如str\n",
    "        else:\n",
    "            # print('\\t\\tcolumns dtype is object and will convert to category')\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    endtime = datetime.datetime.now()\n",
    "    print('consume times: {:.4f}'.format((endtime - starttime).seconds))\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE is: cuda\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED=2020\n",
    "seed_everything(SEED)\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE is:',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path='../../data/user_data/train_{}.pkl'\n",
    "test_data_path='../../data/user_data/test_new.pkl'\n",
    "attr_path='../../data/raw_data/attr.txt'\n",
    "topo_path='../../data/raw_data/topo.txt'\n",
    "model_save_path='../../data/user_data/11_26_nn_v3_weight_loss.pkl'\n",
    "nn_result_save_path='../../data/user_data/nn_sub.csv'\n",
    "prob_save_path='../../data/user_data/nn_preds_0520.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(503556, 105)\n",
      "2\n",
      "(505953, 105)\n",
      "3\n",
      "(507552, 105)\n",
      "4\n",
      "(516549, 105)\n",
      "5\n",
      "(517413, 105)\n",
      "6\n",
      "(492267, 105)\n",
      "7\n",
      "(462417, 105)\n",
      "8\n",
      "(519387, 105)\n",
      "9\n",
      "(518511, 105)\n",
      "10\n",
      "(516024, 105)\n",
      "11\n",
      "(521820, 105)\n",
      "12\n",
      "(522081, 105)\n",
      "13\n",
      "(491574, 105)\n",
      "14\n",
      "(469377, 105)\n",
      "15\n",
      "(519537, 105)\n",
      "16\n",
      "(524658, 105)\n",
      "17\n",
      "(523518, 105)\n",
      "18\n",
      "(528582, 105)\n",
      "19\n",
      "(525174, 105)\n",
      "20\n",
      "(495456, 105)\n",
      "21\n",
      "(465870, 105)\n",
      "22\n",
      "(517290, 105)\n",
      "23\n",
      "(516813, 105)\n",
      "24\n",
      "(512130, 105)\n",
      "25\n",
      "(509850, 105)\n",
      "26\n",
      "(521751, 105)\n",
      "27\n",
      "(478371, 105)\n",
      "28\n",
      "(454839, 105)\n",
      "29\n",
      "(513840, 105)\n",
      "30\n",
      "(510414, 105)\n"
     ]
    }
   ],
   "source": [
    "##### load train \n",
    "train_list=[]\n",
    "for i in range(1,31):\n",
    "    print(i)\n",
    "    t=pd.read_pickle(train_data_path.format(i))\n",
    "    train_list.append(t)\n",
    "    print(train_list[-1].shape)\n",
    "train=pd.concat(train_list,axis=0,sort=True)\n",
    "del train_list,t\n",
    "gc.collect()\n",
    "##### load test\n",
    "test=pd.read_pickle(test_data_path)\n",
    "##### change some type\n",
    "cols=['link','label','current_slice_id','future_slice_id']\n",
    "for col in cols:\n",
    "    train[col]=train[col].astype(int)\n",
    "    test[col]=test[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load attr\n",
    "attr_df=pd.read_csv(attr_path,sep='\\t',header=None)\n",
    "attr_df.columns=['link','length','direction','path_class','speed_class','LaneNum','speed_limit','level','width']\n",
    "#####scale some feat\n",
    "attr_df['width']=(attr_df['width'].values-np.mean(attr_df['width'].values))/np.std(attr_df['width'].values)\n",
    "attr_df['length']=(attr_df['length'].values-np.mean(attr_df['length'].values))/np.std(attr_df['length'].values)\n",
    "attr_df['speed_limit']=(attr_df['speed_limit'].values-np.mean(attr_df['speed_limit'].values))/np.std(attr_df['speed_limit'].values)\n",
    "train=train.merge(attr_df,on='link',how='left')\n",
    "test=test.merge(attr_df,on='link',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些类别特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### cate: day week_day hour time_gap\n",
    "test['day']=32\n",
    "train['week_day']=train['day'].apply(lambda x:x%7)\n",
    "test['week_day']=4\n",
    "\n",
    "train['hour']=train['future_slice_id'].apply(lambda x:x//30 if x>=0 else (720+x)//30)\n",
    "test['hour']=test['future_slice_id'].apply(lambda x:x//30 if x>=0 else (720+x)//30)\n",
    "\n",
    "train['time_gap']=list(map(lambda x,y: x-y if y>=0 else x-y,train['future_slice_id'], train['current_slice_id']))\n",
    "test['time_gap']=list(map(lambda x,y: x-y if y>=0 else x-y,test['future_slice_id'], test['current_slice_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图拓扑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "683423it [00:59, 11546.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "684813"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##获取下一个链接\n",
    "topo_df=pd.read_csv(topo_path,sep='\\t',header=None)\n",
    "\n",
    "topo_df.columns=['link','next_link']\n",
    "topo_df['next_link']=topo_df['next_link'].apply(lambda x: [ int(i) for i in x.split(',')])\n",
    "all_topo_link=set(list(topo_df['link'].values))\n",
    "len(all_topo_link)\n",
    "for _,row in tqdm(topo_df.iterrows()):\n",
    "    next_link=row['next_link']\n",
    "    for link in next_link:\n",
    "        if link not in all_topo_link:all_topo_link.add(link)\n",
    "len(all_topo_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.merge(topo_df,on='link',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.merge(topo_df,on='link',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征-->id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:01<00:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direction or: 3\n",
      "direction new: 3\n",
      "directiontest or: 3\n",
      "directiontest new: 3\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 3/14 [00:01<00:06,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_class or: 5\n",
      "path_class new: 5\n",
      "path_classtest or: 5\n",
      "path_classtest new: 5\n",
      "**************************************************\n",
      "speed_class or: 7\n",
      "speed_class new: 7\n",
      "speed_classtest or: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:01<00:03,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed_classtest new: 7\n",
      "**************************************************\n",
      "LaneNum or: 3\n",
      "LaneNum new: 3\n",
      "LaneNumtest or: 3\n",
      "LaneNumtest new: 3\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 6/14 [00:01<00:02,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level or: 5\n",
      "level new: 5\n",
      "leveltest or: 5\n",
      "leveltest new: 5\n",
      "**************************************************\n",
      "time_gap or: 30\n",
      "time_gap new: 30\n",
      "time_gaptest or: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 10/14 [00:02<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_gaptest new: 30\n",
      "**************************************************\n",
      "current_slice_id or: 749\n",
      "current_slice_id new: 749\n",
      "current_slice_idtest or: 641\n",
      "current_slice_idtest new: 641\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 12/14 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future_slice_id or: 720\n",
      "future_slice_id new: 720\n",
      "future_slice_idtest or: 709\n",
      "future_slice_idtest new: 709\n",
      "**************************************************\n",
      "week_day or: 7\n",
      "week_day new: 7\n",
      "week_daytest or: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week_daytest new: 1\n",
      "**************************************************\n",
      "hour or: 24\n",
      "hour new: 24\n",
      "hourtest or: 24\n",
      "hourtest new: 24\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "col_thre_dict={'link':0.5, 'direction':0.5, 'path_class':0.5, 'speed_class':0.5, 'LaneNum':0.5, 'level':0.5, 'continuous_width':0.5,\n",
    "               'continuous_length':0.5,'continuous_speed_limit':0.5,'time_gap':0,\n",
    "              'current_slice_id':0.5,'future_slice_id':0.5,'week_day':0,'hour':0}\n",
    "len(col_thre_dict)\n",
    "\n",
    "ids_indexs={}\n",
    "mp_col_ids_indexs={}\n",
    "ids_indexs['padding']=0\n",
    "for col,thre in tqdm(col_thre_dict.items()):\n",
    "    mp={}\n",
    "    unknow=None\n",
    "    #连续特征一个field\n",
    "    if 'continuous_' in col:\n",
    "        mp[col]=len(ids_indexs)\n",
    "        ids_indexs[col]=len(ids_indexs)\n",
    "        unknow=len(ids_indexs)\n",
    "        ids_indexs[col+'_unknow']=len(ids_indexs)\n",
    "        mp_col_ids_indexs[col]=[mp,unknow]\n",
    "        continue\n",
    "    if col=='link':\n",
    "        curr_len=len(ids_indexs)\n",
    "        ###use attr\n",
    "        for i,ids in enumerate(attr_df['link'].values):\n",
    "            ids_indexs[col+'_'+str(ids)]=i+curr_len\n",
    "            mp[ids]=i+curr_len\n",
    "        if thre!=0:\n",
    "            unknow=len(ids_indexs)\n",
    "            ids_indexs[col+'_unknow']=len(ids_indexs)\n",
    "        mp_col_ids_indexs[col]=[mp,unknow]\n",
    "        continue\n",
    "    t=train[col].value_counts().reset_index()\n",
    "    print(col+' or:',len(t))\n",
    "    all_ids=t[t[col]>thre]['index'].values\n",
    "    print(col+' new:',len(all_ids))\n",
    "    print(col+'test or:',test[col].nunique())\n",
    "    print(col+'test new:',test[test[col].isin(all_ids)][col].nunique())\n",
    "    print('*'*50)\n",
    "    curr_len=len(ids_indexs)\n",
    "    for i,ids in enumerate(all_ids):\n",
    "        ids_indexs[col+'_'+str(ids)]=i+curr_len\n",
    "        mp[ids]=i+curr_len\n",
    "    if thre!=0:\n",
    "        unknow=len(ids_indexs)\n",
    "        ids_indexs[col+'_unknow']=len(ids_indexs)\n",
    "    mp_col_ids_indexs[col]=[mp,unknow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:07<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "feat_columns=[] \n",
    "feat_value_columns=[] \n",
    "for col,thre in tqdm(col_thre_dict.items()):\n",
    "    col_index_name='{}_index'.format(col)\n",
    "    col_value_name='{}_value'.format(col)\n",
    "    feat_columns.append(col_index_name)\n",
    "    feat_value_columns.append(col_value_name)\n",
    "    real_col=col\n",
    "    #continuous feat\n",
    "    if 'continuous_' in col:\n",
    "        real_col=col.replace('continuous_','')\n",
    "        train[col_index_name]=mp_col_ids_indexs[col][0][col]\n",
    "        train[col_value_name]=train[real_col].values\n",
    "        \n",
    "        test[col_index_name]=mp_col_ids_indexs[col][0][col]\n",
    "        test[col_value_name]=test[real_col].values\n",
    "    # cate feat\n",
    "    else:\n",
    "        mp=mp_col_ids_indexs[col][0]\n",
    "        unknow=mp_col_ids_indexs[col][1]\n",
    "        if unknow!=None:\n",
    "            train[col_index_name]=train[real_col].map(mp).fillna(unknow)\n",
    "            test[col_index_name]=test[real_col].map(mp).fillna(unknow)\n",
    "        else:\n",
    "            train[col_index_name]=train[real_col].map(mp)\n",
    "            test[col_index_name]=test[real_col].map(mp)\n",
    "        train[col_value_name]=1.\n",
    "        test[col_value_name]=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取子图拓扑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "683423it [01:09, 9818.36it/s] \n"
     ]
    }
   ],
   "source": [
    "##获取上一个链接\n",
    "mp=mp_col_ids_indexs['link'][0]\n",
    "unknow=mp_col_ids_indexs['link'][1]\n",
    "link_before_dict={}\n",
    "for _,row in tqdm(topo_df.iterrows()):\n",
    "    link=row['link']\n",
    "    link=mp[link]\n",
    "    next_link=row['next_link']\n",
    "    for next_l in next_link:\n",
    "        next_l=mp[next_l]\n",
    "        if next_l not in link_before_dict:link_before_dict[next_l]=[]\n",
    "        if link not in link_before_dict[next_l]:\n",
    "            link_before_dict[next_l]=link_before_dict[next_l]+[link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "683423it [01:08, 10020.99it/s]\n"
     ]
    }
   ],
   "source": [
    "##获取下一个链接\n",
    "mp=mp_col_ids_indexs['link'][0]\n",
    "unknow=mp_col_ids_indexs['link'][1]\n",
    "link_next_dict={}\n",
    "for _,row in tqdm(topo_df.iterrows()):\n",
    "    link=row['link']\n",
    "    link=mp[link]\n",
    "    next_link=row['next_link']\n",
    "    link_next_dict[link]=[]\n",
    "    for next_l in next_link:\n",
    "        next_l=mp[next_l]\n",
    "        link_next_dict[link]=link_next_dict[link]+[next_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15569"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'可以做拓扑关系的link(已经转换成id)'\n",
    "train_test_link=[]\n",
    "for link in train['link'].unique():\n",
    "    if link in all_topo_link:\n",
    "        train_test_link:train_test_link.append(mp[link])\n",
    "for link in test['link'].unique():\n",
    "    if link in all_topo_link:\n",
    "        train_test_link.append(mp[link])\n",
    "train_test_link=list(set(train_test_link))\n",
    "len(train_test_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15569/15569 [03:02<00:00, 85.44it/s] \n"
     ]
    }
   ],
   "source": [
    "def get_next_link(link_id):\n",
    "    '获取下游'\n",
    "    next_link=link_next_dict.get(link_id,[]) #下游\n",
    "    return [[link_id,next_link_id] for next_link_id in next_link],len(next_link),next_link\n",
    "def get_before_link(link_id):\n",
    "    '获取上游'\n",
    "    before_link=link_before_dict.get(link_id,[]) #下游\n",
    "    return [[link_id,before_link_id]for before_link_id in before_link],len(before_link),before_link\n",
    "\n",
    "def add_link_set(links,link_set,add=True):\n",
    "    n=0\n",
    "    for link in links:\n",
    "        if link not in link_set:\n",
    "            if add:link_set.add(link)\n",
    "            n+=1\n",
    "    return link_set,n\n",
    "\n",
    "def add_link_info(link_add_info,sub_info,num,max_number,link_set):\n",
    "    for info in sub_info:\n",
    "        #都包含节点\n",
    "        if info[1] in link_set and info[0] in link_set:\n",
    "            link_add_info.append(info)\n",
    "        #都不在\n",
    "        elif info[1] not in link_set and info[0]  not in link_set:\n",
    "            if num>max_number-2:continue\n",
    "            link_set.add(info[1])\n",
    "            link_set.add(info[0])\n",
    "            link_add_info.append(info)\n",
    "            num+=2\n",
    "        #0在\n",
    "        elif info[1] not in link_set:\n",
    "            if num>max_number-1:continue\n",
    "            link_set.add(info[1])\n",
    "            link_add_info.append(info)\n",
    "            num+=1\n",
    "        #1在\n",
    "        elif info[0] not in link_set:\n",
    "            if num>max_number-1:continue\n",
    "            link_set.add(info[0])\n",
    "            link_add_info.append(info)\n",
    "            num+=1\n",
    "    return link_add_info,num,link_set\n",
    "\n",
    "\n",
    "def convert_symmetric(X):\n",
    "    '转换成对称矩阵'\n",
    "    X += X.T +np.eye(X.shape[0])\n",
    "    return X\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    D=np.diag(1/np.sqrt(np.sum(adj,axis=1)))\n",
    "    adj=np.dot(D,adj)\n",
    "    return adj.dot(D)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "link_toop_sub_graph={} #link_id:matrix\n",
    "NUM_ADD_GRAPPH=4 #添加图的范围\n",
    "MAX_NUMBER=200 #最大的子图数量\n",
    "nums=[]\n",
    "for link_id in tqdm(train_test_link):\n",
    "    link_info=[] #记录边\n",
    "    link_set=set([link_id])\n",
    "    num=1\n",
    "    next_link=link_next_dict.get(link_id,[]) #下游\n",
    "    before_link=link_before_dict.get(link_id,[]) #上游\n",
    "    \n",
    "    ###当前上下游link\n",
    "    link_set,n=add_link_set(next_link,link_set)\n",
    "    num+=n\n",
    "    link_set,n=add_link_set(before_link,link_set)\n",
    "    num+=n\n",
    "    link_info.extend([[link_id,next_link_id] for next_link_id in next_link])\n",
    "    link_info.extend([[link_id,before_link_id]for before_link_id in before_link])\n",
    "    \n",
    "    link_add_info=[]#其他边\n",
    "    #扩展NUM_ADD_GRAPPH阶\n",
    "    for graph_add in range(NUM_ADD_GRAPPH):\n",
    "        if num==MAX_NUMBER:break\n",
    "        next_link_next=[]\n",
    "        before_link_before=[]\n",
    "        #next link\n",
    "        for sub_link_id in next_link:\n",
    "            sub_info,sub_num,sub_next_link= get_next_link(sub_link_id)\n",
    "            link_add_info,num,link_set=add_link_info(link_add_info,sub_info,num,MAX_NUMBER,link_set)\n",
    "            next_link_next.extend(sub_next_link)\n",
    "            \n",
    "            sub_info,sub_num,sub_next_link= get_before_link(sub_link_id)\n",
    "            link_add_info,num,link_set=add_link_info(link_add_info,sub_info,num,MAX_NUMBER,link_set)\n",
    "            next_link_next.extend(sub_next_link)\n",
    "        #before link（bug：next_link_next：应该是before_link_before 但基本无影响）\n",
    "        for sub_link_id in before_link:\n",
    "            sub_info,sub_num,sub_before_link=get_before_link(sub_link_id)\n",
    "            link_add_info,num,link_set=add_link_info(link_add_info,sub_info,num,MAX_NUMBER,link_set)\n",
    "            next_link_next.extend(sub_before_link)\n",
    "            \n",
    "            sub_info,sub_num,sub_before_link= get_next_link(sub_link_id)\n",
    "            link_add_info,num,link_set=add_link_info(link_add_info,sub_info,num,MAX_NUMBER,link_set)\n",
    "            next_link_next.extend(sub_before_link)\n",
    "        \n",
    "        next_link=next_link_next\n",
    "        before_link=before_link_before\n",
    "    \n",
    "    nums.append(num)\n",
    "    link_info.extend(link_add_info)#所有边\n",
    "    \n",
    "    \n",
    "    #转换成id\n",
    "    edges=np.array(link_info)\n",
    "    link_mp={link_id:0}\n",
    "    k=0\n",
    "    for sub_link_id in set(edges.flatten()):\n",
    "        if sub_link_id!=link_id:\n",
    "            link_mp[sub_link_id]=k+1\n",
    "            k+=1\n",
    "    number=len(link_mp) #当前图的个数\n",
    "    edges = np.array(list(map(link_mp.get, edges.flatten())),\n",
    "                     dtype=np.int32).reshape(edges.shape)\n",
    "    \n",
    "    #转换成稀疏邻接矩阵\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(number, number), dtype=np.float32).toarray()\n",
    "    #获得现在的稀疏矩阵id\n",
    "    link_ids=list(link_mp.keys())\n",
    "    \n",
    "    #paddding后转换成对称矩阵\n",
    "    adj=np.pad(adj, ((0, MAX_NUMBER-number), (0, MAX_NUMBER-number)), mode='constant',constant_values=(0))\n",
    "    adj=convert_symmetric(adj) #对称矩阵\n",
    "    adj=(adj>0).astype(np.int)\n",
    "    \n",
    "    #D-1/2*A*D-1/2\n",
    "    adj=normalize_adj(adj)\n",
    "    #pad link_id\n",
    "    link_ids=link_ids+[0]*(MAX_NUMBER-number)\n",
    "    #save matrix\n",
    "    link_toop_sub_graph[link_id]=(adj,link_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25     , 0.2236068, 0.25     , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.2236068, 0.2      , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.25     , 0.       , 0.25     , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.       , 0.       , ..., 1.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 1.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        1.       ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2, 74.26918877256085)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(nums),np.min(nums),np.mean(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74.269189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.624611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98%</th>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                num\n",
       "count  15569.000000\n",
       "mean      74.269189\n",
       "std       26.624611\n",
       "min        2.000000\n",
       "50%       73.000000\n",
       "90%      108.000000\n",
       "95%      119.000000\n",
       "98%      132.000000\n",
       "99%      144.000000\n",
       "max      200.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'num':nums}).describe([0.9,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每个link 的静态属性特征\n",
    "转换成矩阵后作为nn中的embedding 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attr_feat_cols=['direction', 'path_class', 'speed_class', 'LaneNum', 'level', 'width','length','speed_limit'] #后面三个是连续特征\n",
    "\n",
    "'特征转换成id表示'\n",
    "for col in attr_feat_cols[:5]:\n",
    "    attr_df[col]=attr_df[col].map(mp_col_ids_indexs[col][0])\n",
    "'获得embedding 矩阵'\n",
    "link_embeddding_matrix_cate=attr_df[attr_feat_cols].values\n",
    "link_embeddding_matrix_cate=np.concatenate([np.zeros(len(attr_feat_cols)).reshape(1,-1),link_embeddding_matrix_cate],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del attr_df,mp_col_ids_indexs,link_next_dict,link_before_dict,topo_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scale (序列特征)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:00<00:00, 606355.01it/s]\n",
      "100it [00:25,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "'scale feat'\n",
    "scaled_features=[]\n",
    "for col in tqdm(train.columns):\n",
    "    if 'feature' in col:\n",
    "        scaled_features.append(col)\n",
    "len(scaled_features)\n",
    "means=np.mean(train[scaled_features].values,axis=0)\n",
    "stds=np.std(train[scaled_features].values,axis=0)\n",
    "\n",
    "for i,col in tqdm(enumerate(scaled_features)):\n",
    "    train.loc[:,col]=(train.loc[:,col]-means[i])/stds[i]\n",
    "    test.loc[:,col]=(test.loc[:,col]-means[i])/stds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'recent_feature 序列'\n",
    "recent_cols=[]\n",
    "for i in range(1,6):\n",
    "    recent_col=[ col for col in train.columns if 'recent_feature_{}'.format(i) in col]\n",
    "    recent_cols.extend(recent_col)\n",
    "train['recent_split_info']=[ i.reshape(4,5).reshape(5,4) for i in train[recent_cols].values]\n",
    "test['recent_split_info']=[ i.reshape(4,5).reshape(5,4) for i in test[recent_cols].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'history_feature 序列'\n",
    "his_cols=[]\n",
    "for i in range(1,6):\n",
    "    his_col=[ col for col in train.columns if 'history_feature_cycle{}'.format(i) in col]\n",
    "    his_cols.extend(his_col)\n",
    "len(his_cols)\n",
    "train['his_split_info']=[ i.reshape(4,20).reshape(20,4) for i in train[his_cols].values]\n",
    "test['his_split_info']=[ i.reshape(4,20).reshape(20,4) for i in test[his_cols].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label']=train['label'].apply(lambda x: x-1 if x!=4 else 2)\n",
    "test['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model_data(df):\n",
    "    df['category_features']=[ i for i in df[feat_columns].values]\n",
    "    df['category_features_values']=[ i for i in df[feat_value_columns].values]\n",
    "    return df[['category_features','category_features_values','recent_split_info','his_split_info','link_index','label']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=get_model_data(train.iloc[:20000,:])\n",
    "test_data=get_model_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zy_DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,graph_dict=link_toop_sub_graph):\n",
    "        self.data=data\n",
    "        self.graph_dict=graph_dict\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_graph_feat(self,link_id):\n",
    "        if link_id not in self.graph_dict:\n",
    "            return [link_id]+[0]*(MAX_NUMBER-1),np.eye(MAX_NUMBER)\n",
    "        link_graph,link_seq=self.graph_dict[link_id]\n",
    "        return link_seq,link_graph\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        feature=self.data[index,:]\n",
    "        category_index=torch.tensor(feature[0],dtype=torch.long)  #label\n",
    "        category_value=torch.tensor(feature[1],dtype=torch.float32)    \n",
    "        recent_split_info=torch.tensor(feature[2],dtype=torch.float32)   \n",
    "        his_split_info=torch.tensor(feature[3],dtype=torch.float32)\n",
    "        \n",
    "        link_index=feature[4]\n",
    "        link_seq,link_graph=self.get_graph_feat(link_index)\n",
    "        link_seq=torch.tensor(link_seq,dtype=torch.long)\n",
    "        link_graph=torch.tensor(link_graph,dtype=torch.float32)\n",
    "        \n",
    "        label=torch.tensor(feature[5],dtype=torch.long)\n",
    "        return category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        category_index = torch.stack([x[0] for x in batch])\n",
    "        category_value = torch.stack([x[1] for x in batch])\n",
    "        recent_split_info = torch.stack([x[2] for x in batch])\n",
    "        his_split_info = torch.stack([x[3] for x in batch])\n",
    "        link_seq = torch.stack([x[4] for x in batch])\n",
    "        link_graph = torch.stack([x[5] for x in batch])\n",
    "        label = torch.stack([x[6] for x in batch])\n",
    "        return category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())\n",
    "    \n",
    "\n",
    "def get_loader(df,batch_size=16,train_mode=False):\n",
    "    ds_df = zy_DataSet(df)\n",
    "    loader = DataLoaderX(ds_df, batch_size=batch_size, shuffle=train_mode, num_workers=2, collate_fn=ds_df.collate_fn, drop_last=train_mode)\n",
    "    loader.num = len(ds_df)\n",
    "    return loader\n",
    "    \n",
    "def debug_loader(d):\n",
    "    loader=get_loader(d,train_mode=True)\n",
    "    for category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label in loader:\n",
    "        print(category_index)\n",
    "        print(category_value)\n",
    "        print(recent_split_info)\n",
    "        print(his_split_info)\n",
    "        print(label)\n",
    "        print(link_seq.size())\n",
    "        print(link_graph.size())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[650595, 686109, 686111, 686118, 686126, 686129, 686135, 686137, 686139,\n",
      "         686155, 686280, 687121, 687643, 687653],\n",
      "        [317356, 686108, 686113, 686117, 686125, 686131, 686135, 686137, 686139,\n",
      "         686169, 686326, 687142, 687643, 687653],\n",
      "        [515797, 686109, 686111, 686117, 686125, 686129, 686135, 686137, 686139,\n",
      "         686147, 686171, 686949, 687643, 687650],\n",
      "        [352712, 686109, 686112, 686118, 686126, 686130, 686135, 686137, 686139,\n",
      "         686163, 686474, 687284, 687643, 687659],\n",
      "        [674656, 686109, 686111, 686118, 686126, 686129, 686135, 686137, 686139,\n",
      "         686154, 686577, 687320, 687643, 687662],\n",
      "        [ 39705, 686107, 686111, 686117, 686125, 686129, 686135, 686137, 686139,\n",
      "         686142, 686458, 687180, 687643, 687655],\n",
      "        [561423, 686108, 686112, 686117, 686125, 686130, 686135, 686137, 686139,\n",
      "         686165, 686510, 687273, 687643, 687660],\n",
      "        [376266, 686107, 686111, 686117, 686125, 686129, 686135, 686137, 686139,\n",
      "         686163, 686254, 687038, 687643, 687653],\n",
      "        [358566, 686107, 686112, 686117, 686125, 686130, 686135, 686137, 686139,\n",
      "         686159, 686207, 686983, 687643, 687649],\n",
      "        [192971, 686107, 686112, 686117, 686125, 686130, 686135, 686137, 686139,\n",
      "         686150, 686475, 687183, 687643, 687656],\n",
      "        [310582, 686108, 686112, 686117, 686125, 686130, 686135, 686137, 686139,\n",
      "         686141, 686770, 687540, 687643, 687670],\n",
      "        [  3870, 686107, 686111, 686119, 686126, 686129, 686135, 686137, 686139,\n",
      "         686162, 686534, 687267, 687643, 687659],\n",
      "        [507946, 686107, 686112, 686117, 686125, 686130, 686135, 686137, 686139,\n",
      "         686163, 686232, 686991, 687643, 687651],\n",
      "        [ 70417, 686107, 686111, 686117, 686125, 686129, 686135, 686137, 686139,\n",
      "         686159, 686630, 687361, 687643, 687664],\n",
      "        [468567, 686109, 686111, 686118, 686126, 686129, 686135, 686137, 686139,\n",
      "         686157, 686258, 687001, 687643, 687652],\n",
      "        [508094, 686107, 686113, 686117, 686125, 686131, 686135, 686137, 686139,\n",
      "         686142, 686677, 687404, 687643, 687663]])\n",
      "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.2232,\n",
      "          0.8980,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.4811,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  4.9408, -0.3220,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.3824,\n",
      "          0.8980,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.3000,\n",
      "          0.8980,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.3000,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.4537,\n",
      "          2.5463,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.5031,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.4098,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.1080,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.3604,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -0.9253,  0.2816,\n",
      "         -0.4756,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.4811,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -0.9253,  0.0621,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.2891,\n",
      "          0.8980,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.5412, -0.2013,\n",
      "          1.9968,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]])\n",
      "tensor([[[-0.1502, -0.7079, -0.0648, -1.9216],\n",
      "         [-0.1509, -0.7083, -0.0657, -1.9237],\n",
      "         [-2.1323, -0.7658, -2.4977, -1.9275],\n",
      "         [-2.1364, -0.7666, -2.5025, -1.9329],\n",
      "         [ 0.1311, -0.7107, -0.0686, -1.9394]],\n",
      "\n",
      "        [[-0.9619,  1.1674,  0.5738, -0.2766],\n",
      "         [-0.9326,  1.3946, -1.9673,  3.0131],\n",
      "         [-0.9271,  1.9063, -1.9467,  3.0141],\n",
      "         [-1.2215,  2.3046, -2.0642,  3.0164],\n",
      "         [-1.3245,  2.3615, -2.1493,  4.6708]],\n",
      "\n",
      "        [[ 0.8759, -0.3669,  0.3637, -0.2766],\n",
      "         [ 0.8762, -0.3673,  0.3713, -0.2781],\n",
      "         [ 0.8768, -0.3678,  0.4032, -0.2803],\n",
      "         [ 0.7005, -0.4822, -0.0109, -0.2831],\n",
      "         [ 0.2620, -0.5969, -0.1255, -0.2869]],\n",
      "\n",
      "        [[-0.5560, -0.3101, -0.6064, -0.2766],\n",
      "         [-0.6950, -0.3105, -0.5512, -0.2781],\n",
      "         [-0.5433, -0.4246, -0.7879, -0.2803],\n",
      "         [-0.5450, -0.4254, -1.0335,  1.3667],\n",
      "         [-0.6083, -0.4831, -0.5563, -0.2869]],\n",
      "\n",
      "        [[-1.6280, -0.5942, -2.1343,  4.6586],\n",
      "         [-1.6301, -0.5946, -2.0159,  3.0131],\n",
      "         [-1.3263, -0.4815, -1.4038,  1.3669],\n",
      "         [-1.1293, -0.4254, -1.7802,  3.0164],\n",
      "         [-0.9933, -0.5400, -1.3690,  1.3657]],\n",
      "\n",
      "        [[-1.0461, -0.5942, -0.9783,  1.3685],\n",
      "         [-1.1779, -0.5946, -1.3199,  1.3675],\n",
      "         [-0.4205, -0.3109, -0.3828, -0.2803],\n",
      "         [-0.3835, -0.0841, -0.8631,  1.3667],\n",
      "         [-0.3618, -0.0280, -0.9301,  1.3657]],\n",
      "\n",
      "        [[-0.0506,  0.2582, -0.2507, -0.2766],\n",
      "         [-0.0512,  0.2010, -0.2356, -0.2781],\n",
      "         [-0.1595,  0.2576,  0.3222, -0.2803],\n",
      "         [-0.4604, -0.0841,  0.2407, -0.2831],\n",
      "         [-0.2694, -0.1986,  0.3947, -0.2869]],\n",
      "\n",
      "        [[-0.4029, -0.7079, -0.9298,  1.3685],\n",
      "         [-0.4038, -0.7083, -1.8864,  3.0131],\n",
      "         [-1.5719, -0.6521, -1.9386,  3.0141],\n",
      "         [-1.6982, -0.5960, -1.7477,  3.0164],\n",
      "         [-0.1385, -0.6538, -1.6128,  3.0182]],\n",
      "\n",
      "        [[-0.5101,  0.0877, -0.6226,  1.3685],\n",
      "         [-0.2505,  0.2010, -1.0853,  1.3675],\n",
      "         [-0.1595,  0.5418, -0.6097,  1.3669],\n",
      "         [-0.0760,  0.6553, -1.1552,  1.3667],\n",
      "         [-0.3772,  0.7685, -1.1252,  1.3657]],\n",
      "\n",
      "        [[-0.2727,  0.0877,  0.8810, -0.2766],\n",
      "         [-0.5188,  0.1442,  0.4118, -0.2781],\n",
      "         [-0.7659,  0.6555,  0.3384, -0.2803],\n",
      "         [-0.8525,  0.5984,  0.7114, -0.2831],\n",
      "         [-0.7777,  0.5978,  0.9555, -0.2869]],\n",
      "\n",
      "        [[ 1.5191, -0.1964,  0.8972, -0.2766],\n",
      "         [ 1.5967, -0.2536,  0.8083, -0.2781],\n",
      "         [ 1.5216, -0.3678,  1.1487, -0.2803],\n",
      "         [ 1.1771, -0.4254,  1.1334, -0.2831],\n",
      "         [ 1.1784, -0.4831,  1.0530, -0.2869]],\n",
      "\n",
      "        [[ 0.5160, -0.6510, -0.2588, -0.2766],\n",
      "         [-0.5494, -0.5946,  0.0314, -0.2781],\n",
      "         [-0.6891, -0.5952,  0.2331, -0.2803],\n",
      "         [-0.6910, -0.5960,  0.2326, -0.2831],\n",
      "         [-0.6930, -0.6538,  0.2646, -0.2869]],\n",
      "\n",
      "        [[-0.0813,  0.0877, -0.3558, -0.2766],\n",
      "         [-0.0052,  0.2579, -0.2923, -0.2781],\n",
      "         [-0.0059,  0.4850, -0.2855, -0.2803],\n",
      "         [ 0.0239,  0.2571, -0.3599, -0.2831],\n",
      "         [-0.0076,  0.4841, -0.1011, -0.2869]],\n",
      "\n",
      "        [[-0.6862, -0.5942, -0.4528, -0.2766],\n",
      "         [-0.6491, -0.5378, -0.1142, -0.2781],\n",
      "         [ 0.1706, -0.5384, -0.1073, -0.2803],\n",
      "         [ 0.1700, -0.5391, -0.1083, -0.2831],\n",
      "         [ 0.1927, -0.5400, -0.1093, -0.2869]],\n",
      "\n",
      "        [[ 0.8759, -0.7079, -0.3396, -0.2766],\n",
      "         [ 0.8762, -0.7083, -0.3408, -0.2781],\n",
      "         [ 0.8768, -0.7089, -0.3423, -0.2803],\n",
      "         [ 0.8773, -0.7097, -0.3436, -0.2831],\n",
      "         [ 0.8781, -0.7107, -0.3450, -0.2869]],\n",
      "\n",
      "        [[ 0.3475, -0.3101,  1.0750, -0.2766],\n",
      "         [ 0.4316, -0.1400,  1.2938, -0.2781],\n",
      "         [ 0.4393, -0.1404,  1.4890, -0.2803],\n",
      "         [ 1.1310, -0.3685,  1.5230, -0.2831],\n",
      "         [ 1.1322, -0.3693,  1.1424, -0.2869]]])\n",
      "tensor([[[-1.0813, -0.5829, -0.1926, -0.2355],\n",
      "         [-1.0815, -0.5828, -1.2928,  1.4038],\n",
      "         [-1.2829, -0.5827, -0.9554,  1.4054],\n",
      "         ...,\n",
      "         [-0.4207, -0.6514, -0.5508, -0.2794],\n",
      "         [-0.3672, -0.7091, -0.5348, -0.2793],\n",
      "         [-0.3674, -0.7091, -0.5350, -0.2787]],\n",
      "\n",
      "        [[-0.7306,  1.8005,  0.2868, -0.2355],\n",
      "         [-0.7905,  1.6814,  0.0514, -0.2357],\n",
      "         [-0.8800,  1.9195, -0.1299, -0.2350],\n",
      "         ...,\n",
      "         [-0.8109,  1.3687,  0.1763, -0.2794],\n",
      "         [-0.8109,  1.4840,  0.8873, -0.2793],\n",
      "         [-0.7880,  1.6572,  0.7017, -0.2787]],\n",
      "\n",
      "        [[ 0.4858, -0.4041, -0.3104, -0.2355],\n",
      "         [ 0.6348, -0.4637, -0.3574, -0.2357],\n",
      "         [ 0.6122, -0.5231, -0.3736, -0.2350],\n",
      "         ...,\n",
      "         [ 0.5816, -0.7092, -0.0580, -0.2794],\n",
      "         [ 0.5815, -0.7091, -0.0581, -0.2793],\n",
      "         [ 0.5811, -0.7091, -0.0258, -0.2787]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3052, -0.4041, -0.6720,  1.4038],\n",
      "         [-0.2532, -0.4637, -0.3259, -0.2357],\n",
      "         [-0.2533, -0.4040, -0.8060,  1.4054],\n",
      "         ...,\n",
      "         [-0.1070, -0.5360, -1.4960,  1.3568],\n",
      "         [-0.7115, -0.5937, -1.5528,  2.9935],\n",
      "         [-0.5586, -0.4782, -1.1977,  1.3571]],\n",
      "\n",
      "        [[ 1.4186, -0.6425, -0.0511, -0.2355],\n",
      "         [ 1.4183, -0.6424, -0.0429, -0.2357],\n",
      "         [ 1.1942, -0.5827, -0.1849, -0.2350],\n",
      "         ...,\n",
      "         [ 0.9489, -0.7092,  0.1198, -0.2794],\n",
      "         [ 0.9487, -0.7091,  0.1197, -0.2793],\n",
      "         [ 0.9176, -0.6514,  0.3218, -0.2787]],\n",
      "\n",
      "        [[-0.2157,  0.8472,  0.4833, -0.2355],\n",
      "         [-0.0592,  0.8472,  0.8139, -0.2357],\n",
      "         [ 0.1869,  0.8471,  1.4659, -0.2350],\n",
      "         ...,\n",
      "         [-0.1988,  0.7915,  0.5641, -0.2794],\n",
      "         [-0.7574,  0.9068,  0.6772, -0.2793],\n",
      "         [-0.4515,  0.9069,  0.5319, -0.2787]]])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([16, 200])\n",
      "torch.Size([16, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "debug_loader(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################Bi\n",
    "class Bi_interaction(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bi_interaction, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        index = square_of_sum - sum_of_square\n",
    "        return 0.5 * index\n",
    "    \n",
    "##################GCN\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "            super(GraphConvolution, self).__init__()\n",
    "            self.in_features = in_features\n",
    "            self.out_features = out_features\n",
    "            self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "            if bias:\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "            else:\n",
    "                self.register_parameter('bias', None)\n",
    "    \n",
    "            self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "            nn.init.kaiming_uniform_(self.weight)\n",
    "            if self.bias is not None:\n",
    "                nn.init.zeros_(self.bias)\n",
    "    \n",
    "    def forward(self, input, adj):\n",
    "            support = torch.matmul(input, self.weight)\n",
    "            output = torch.matmul(adj, support)\n",
    "            if self.bias is not None:\n",
    "                return F.relu(output + self.bias)\n",
    "            else:\n",
    "                return F.relu(output)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "                self.in_features, self.out_features, self.bias is not None\n",
    "            )\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,feat_dim,K=2):\n",
    "        self.K=K\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcs=nn.ModuleList([GraphConvolution(feat_dim,feat_dim) for _ in range(K)])\n",
    "    \n",
    "    def forward(self,A,H):\n",
    "        for k in range(self.K):\n",
    "            H=self.gcs[k](H,A)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Model parameters: 28431964\n"
     ]
    }
   ],
   "source": [
    "class DiDi_Model(nn.Module):\n",
    "    def __init__(self,embedding_num,embedding_dim,field_dims=None):\n",
    "        '''\n",
    "        field_dims：the number of fileds\n",
    "        embedding_num : sum of the index of all fields\n",
    "        embedding_dim : the dim of embedding\n",
    "        '''\n",
    "        super(DiDi_Model, self).__init__()\n",
    "        self.model_name = 'zy_Model'\n",
    "        self.field_dims=field_dims\n",
    "        self.embedding_num=embedding_num\n",
    "        self.embedding_dim=embedding_dim\n",
    "        \n",
    "        \n",
    "        #link原始特征embedding\n",
    "        self.link_or_em=nn.Embedding(link_embeddding_matrix_cate.shape[0],link_embeddding_matrix_cate.shape[1])\n",
    "        self.link_or_em.weight.data.copy_(torch.from_numpy(link_embeddding_matrix_cate))\n",
    "        self.link_or_em.requires_grad = False\n",
    "        \n",
    "        self.width_em=nn.Sequential(nn.Linear(1,self.embedding_dim))\n",
    "        self.length_em=nn.Sequential(nn.Linear(1,self.embedding_dim))\n",
    "        self.speed_em=nn.Sequential(nn.Linear(1,self.embedding_dim))\n",
    "        \n",
    "        #FM的一阶\n",
    "        self.first_em=nn.Embedding(self.embedding_num,1)\n",
    "        #FM的二阶\n",
    "        self.embdedding_seq=nn.Embedding(self.embedding_num,embedding_dim)\n",
    "        self.bi = Bi_interaction()\n",
    "        \n",
    "        #lstm\n",
    "        input_dim=4\n",
    "        output_put_dim=8\n",
    "        self.lstm_seq=nn.LSTM(input_dim,output_put_dim,2,batch_first=True,bidirectional=False)\n",
    "        self.lstm_seq_1=nn.LSTM(input_dim,output_put_dim,2,batch_first=True,bidirectional=False)\n",
    "        \n",
    "        #GAE\n",
    "        self.gcn=GCN(K=2,feat_dim=9*32)\n",
    "        \n",
    "\n",
    "        self.embed_output_dim = embedding_dim+output_put_dim*2+output_put_dim*2*4+9*32\n",
    "\n",
    "        self.mlp=nn.Sequential(\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(self.embed_output_dim,self.embed_output_dim//2),\n",
    "                               nn.BatchNorm1d(self.embed_output_dim//2),\n",
    "                               nn.ReLU(True),\n",
    "                               nn.Dropout(0.3),\n",
    "                               nn.Linear(self.embed_output_dim//2,3))\n",
    "        \n",
    "    def mask_mean(self,x,mask=None):\n",
    "        if mask!=None:\n",
    "            mask_x=x*(mask.unsqueeze(-1))\n",
    "            x_sum=torch.sum(mask_x,dim=1)\n",
    "            re_x=torch.div(x_sum,torch.sum(mask,dim=1).unsqueeze(-1))\n",
    "        else:\n",
    "            x_sum=torch.sum(x,dim=1)\n",
    "            re_x=torch.div(x_sum,x.size()[1])\n",
    "        return re_x\n",
    "    \n",
    "    \n",
    "    def mask_max(self,x,mask=None):\n",
    "        if mask!=None:\n",
    "            mask=mask.unsqueeze(-1)\n",
    "            mask_x=x-(1-mask)*1e10\n",
    "            x_max=torch.max(mask_x,dim=1)\n",
    "        else:\n",
    "            x_max=torch.max(x,dim=1)\n",
    "        return x_max[0]\n",
    "\n",
    "    def forward(self,category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label,is_test=False):\n",
    "        \n",
    "        batch_size=category_index.size()[0]\n",
    "        \n",
    "        ##FM二阶\n",
    "        seq_em=self.embdedding_seq(category_index)*category_value.unsqueeze(2)\n",
    "        x2=self.bi(seq_em)\n",
    "        \n",
    "        #lstm\n",
    "        f,_=self.lstm_seq_1(recent_split_info)\n",
    "        fmax=self.mask_max(f)\n",
    "        fmean=self.mask_mean(f)\n",
    "        recent_features=torch.cat([fmean,fmax],dim=1)\n",
    "        \n",
    "        \n",
    "        his_features=[]\n",
    "        for i in range(4):\n",
    "            his_split_info_sample=his_split_info[:,i*5:(i+1)*5,:]\n",
    "            f,_=self.lstm_seq(his_split_info_sample)\n",
    "            fmax=self.mask_max(f)\n",
    "            fmean=self.mask_mean(f)\n",
    "            his_features.append(fmax)\n",
    "            his_features.append(fmean)\n",
    "        his_features=torch.cat(his_features,dim=-1)\n",
    "        \n",
    "        \n",
    "        ###GCN\n",
    "        #######node feat\n",
    "        number_graph_node=link_seq.size(1)\n",
    "        link_feat_link_id=self.embdedding_seq(link_seq)\n",
    "        \n",
    "        link_feat=self.link_or_em(link_seq)# B*number_graph_node*8\n",
    "        link_feat_cate=link_feat[:,:,:5].long() #类别特征  B*number_graph_node*5\n",
    "        link_feat_cate=self.embdedding_seq(link_feat_cate).view(batch_size,number_graph_node,-1)\n",
    "        link_feat_width=self.width_em(link_feat[:,:,5].float().unsqueeze(2)) #类别特征\n",
    "        link_feat_length=self.length_em(link_feat[:,:,6].float().unsqueeze(2)) #类别特征\n",
    "        link_feat_speed=self.speed_em(link_feat[:,:,7].float().unsqueeze(2)) #类别特征\n",
    "        link_feat=torch.cat([link_feat_cate,link_feat_width,link_feat_length,link_feat_speed,link_feat_link_id],dim=-1) # B*node*(dim*8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        gcn_out=self.gcn(link_graph,link_feat)\n",
    "        gcn_out=gcn_out[:,0,:].squeeze()\n",
    "        \n",
    "\n",
    "        \n",
    "        #DNN全连接\n",
    "        x2=torch.cat([x2,recent_features,his_features,gcn_out],dim=1)\n",
    "        x3=self.mlp(x2)\n",
    "        \n",
    "        out=x3\n",
    "        if not is_test:\n",
    "            loss_fun=nn.CrossEntropyLoss(torch.tensor([0.1,0.3,0.6]).to(DEVICE))\n",
    "            loss=loss_fun(out,label)\n",
    "            return loss,F.softmax(out,dim=1)\n",
    "        else:\n",
    "            loss_fun=nn.CrossEntropyLoss()\n",
    "            loss=loss_fun(out,label)\n",
    "            return loss,F.softmax(out,dim=1)\n",
    "net = DiDi_Model(field_dims=len(col_thre_dict),embedding_num=len(ids_indexs),embedding_dim=32)\n",
    "print('# Model parameters:', sum(param.numel() for param in net.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_label(d):\n",
    "    loader=get_loader(d[:10000,:],train_mode=True,batch_size=2)\n",
    "\n",
    "    model=DiDi_Model(embedding_num=len(ids_indexs),embedding_dim=32)\n",
    "\n",
    "    for category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label  in loader:\n",
    "        print(category_index.size())\n",
    "        print(category_value.size())\n",
    "        print(recent_split_info.size())\n",
    "        print(his_split_info.size())\n",
    "        y = model(category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label,is_test=False)\n",
    "        print(y)\n",
    "        y = model(category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label,is_test=True)\n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# debug_label(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def metric_fn(preds,real_labels):\n",
    "    ##for log\n",
    "    preds=np.argmax(preds,axis=1)\n",
    "    f1=f1_score(real_labels, preds,average=None)\n",
    "    print(f1)\n",
    "    return 0.2*f1[0]+0.2*f1[1]+0.6*f1[2]\n",
    "\n",
    "def validation_fn(model,val_loader,is_test=False):\n",
    "    model.eval()\n",
    "    bar = tqdm(val_loader)\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    weights=[]\n",
    "    loss_all=[]\n",
    "    for i,feat in enumerate(bar):\n",
    "        category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label=(_.to(DEVICE) for _ in feat)\n",
    "        loss,p= model(category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label,is_test=True)\n",
    "        preds.append(p.detach().cpu().numpy())\n",
    "        labels.append(label.detach().cpu().numpy())\n",
    "        loss_all.append(loss.item())\n",
    "    preds=np.concatenate(preds)\n",
    "    labels=np.concatenate(labels)\n",
    "    if not is_test:\n",
    "        score=metric_fn(preds.squeeze(),labels)\n",
    "        return np.mean(loss_all),score\n",
    "    else:\n",
    "        return preds.squeeze()\n",
    "    \n",
    "\n",
    "def train_model(model,train_loader,val_loader,accumulation_steps=2\n",
    "                ,early_stop_epochs=2,epochs=4,model_save_path='pytorch_zy_model_true.pkl'):  \n",
    "    \n",
    "    losses=[]\n",
    "    \n",
    "    ########早停\n",
    "    no_improve_epochs=0\n",
    "    \n",
    "    ########优化器 学习率\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.99),weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98) #学习率衰减\n",
    "    \n",
    "    train_len=len(train_loader)\n",
    "    \n",
    "    best_vmetric=-np.inf\n",
    "    loss_ages = []\n",
    "    loss_genders=[]\n",
    "    for epoch in range(1,epochs+1):\n",
    "        model.train()\n",
    "        print(scheduler.get_lr()[0])\n",
    "        bar = tqdm(train_loader)\n",
    "        for i,feat in enumerate(bar):\n",
    "            category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label=(_.to(DEVICE) for _ in feat)\n",
    "            loss,_= model(category_index,category_value,recent_split_info,his_split_info,link_seq,link_graph,label,\n",
    "                          is_test=False)\n",
    "            sloss=loss\n",
    "            sloss.backward()\n",
    "            loss_ages.append(loss.item())\n",
    "            loss_genders.append(loss.item())\n",
    "            if (i+1) % accumulation_steps == 0 or (i+1)==train_len:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            bar.set_postfix(loss_ages=np.array(loss_ages).mean(),loss_genders=np.array(loss_genders).mean(),epoch=epoch)\n",
    "#         if scheduler.get_lr()[0]>0.005:\n",
    "        scheduler.step()\n",
    "        #val\n",
    "        val_loss,mse=validation_fn(model,val_loader)\n",
    "        losses.append( 'train_loss:%.5f, score: %.5f, best score: %.5f\\n val loss: %.5f\\n' %\n",
    "            (np.array(loss_ages).mean(),mse,best_vmetric,val_loss))\n",
    "        print(losses[-1])\n",
    "        if mse>=best_vmetric:\n",
    "            torch.save(model.state_dict(),model_save_path)\n",
    "            best_vmetric=mse\n",
    "            no_improve_epochs=0\n",
    "            print('improve save model!!!')\n",
    "        else:\n",
    "            no_improve_epochs+=1\n",
    "        if no_improve_epochs==early_stop_epochs:\n",
    "            print('no improve score !!! stop train !!!')\n",
    "            break\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  train loop single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data=get_model_data(train[train['day']!=30])\n",
    "valid_data=get_model_data(train[train['day']==30])\n",
    "test_data=get_model_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y=train[train['day']==30]['label'].values\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14672160, 6), (510414, 6), (176057, 6))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,valid_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=get_loader(test_data,batch_size=1024,train_mode=False)\n",
    "tra_loader=get_loader(train_data,batch_size=1024,train_mode=True)\n",
    "valid_loader=get_loader(valid_data,batch_size=1024,train_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=DiDi_Model(embedding_num=len(ids_indexs),embedding_dim=32).to(DEVICE) #NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/14328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/14328 [00:04<4:35:19,  1.15s/it, epoch=1, loss_ages=1.12, loss_genders=1.12] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6b0624dd0a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m losses=train_model(model,tra_loader,valid_loader,\n\u001b[1;32m      2\u001b[0m                            \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                            model_save_path=model_save_path)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-17765ef1f060>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, accumulation_steps, early_stop_epochs, epochs, model_save_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m                           is_test=False)\n\u001b[1;32m     56\u001b[0m             \u001b[0msloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0msloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mloss_ages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mloss_genders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses=train_model(model,tra_loader,valid_loader,\n",
    "                           accumulation_steps=1,early_stop_epochs=3,epochs=2,\n",
    "                           model_save_path=model_save_path)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/172 [00:00<?, ?it/s]\u001b[AException in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 779, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 105, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/prefetch_generator/__init__.py\", line 80, in run\n",
      "    for item in self.generator:\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 974, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 941, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 792, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))\n",
      "RuntimeError: DataLoader worker (pid(s) 3551, 3552) exited unexpectedly\n",
      "\n",
      "\n",
      "  1%|          | 1/172 [00:03<09:00,  3.16s/it]\u001b[A\n",
      "  1%|          | 2/172 [00:03<06:23,  2.26s/it]\u001b[A\n",
      "  2%|▏         | 3/172 [00:03<04:45,  1.69s/it]\u001b[A\n",
      "  2%|▏         | 4/172 [00:03<03:26,  1.23s/it]\u001b[A\n",
      "  3%|▎         | 5/172 [00:04<02:41,  1.03it/s]\u001b[A\n",
      "  3%|▎         | 6/172 [00:04<01:59,  1.39it/s]\u001b[A\n",
      "  4%|▍         | 7/172 [00:04<01:38,  1.67it/s]\u001b[A\n",
      "  5%|▍         | 8/172 [00:04<01:15,  2.16it/s]\u001b[A\n",
      "  5%|▌         | 9/172 [00:05<01:07,  2.40it/s]\u001b[A\n",
      "  6%|▌         | 10/172 [00:05<00:54,  2.97it/s]\u001b[A\n",
      "  6%|▋         | 11/172 [00:05<00:53,  2.98it/s]\u001b[A\n",
      "  7%|▋         | 12/172 [00:05<00:44,  3.58it/s]\u001b[A\n",
      "  8%|▊         | 13/172 [00:06<00:45,  3.49it/s]\u001b[A\n",
      "  8%|▊         | 14/172 [00:06<00:38,  4.06it/s]\u001b[A\n",
      "  9%|▊         | 15/172 [00:06<00:41,  3.80it/s]\u001b[A\n",
      "  9%|▉         | 16/172 [00:06<00:35,  4.37it/s]\u001b[A\n",
      " 10%|▉         | 17/172 [00:06<00:39,  3.93it/s]\u001b[A\n",
      " 10%|█         | 18/172 [00:07<00:34,  4.45it/s]\u001b[A\n",
      " 11%|█         | 19/172 [00:07<00:39,  3.84it/s]\u001b[A\n",
      " 12%|█▏        | 20/172 [00:07<00:34,  4.39it/s]\u001b[A\n",
      " 12%|█▏        | 21/172 [00:07<00:36,  4.13it/s]\u001b[A\n",
      " 13%|█▎        | 22/172 [00:08<00:32,  4.66it/s]\u001b[A\n",
      " 13%|█▎        | 23/172 [00:08<00:35,  4.15it/s]\u001b[A\n",
      " 14%|█▍        | 24/172 [00:08<00:31,  4.68it/s]\u001b[A\n",
      " 15%|█▍        | 25/172 [00:08<00:36,  4.01it/s]\u001b[A\n",
      " 15%|█▌        | 26/172 [00:08<00:31,  4.57it/s]\u001b[A\n",
      " 16%|█▌        | 27/172 [00:09<00:36,  4.02it/s]\u001b[A\n",
      " 16%|█▋        | 28/172 [00:09<00:31,  4.57it/s]\u001b[A\n",
      " 17%|█▋        | 29/172 [00:09<00:35,  4.01it/s]\u001b[A\n",
      " 17%|█▋        | 30/172 [00:09<00:31,  4.56it/s]\u001b[A\n",
      " 18%|█▊        | 31/172 [00:10<00:35,  3.99it/s]\u001b[A\n",
      " 19%|█▊        | 32/172 [00:10<00:30,  4.53it/s]\u001b[A\n",
      " 19%|█▉        | 33/172 [00:10<00:35,  3.89it/s]\u001b[A\n",
      " 20%|█▉        | 34/172 [00:10<00:31,  4.44it/s]\u001b[A\n",
      " 20%|██        | 35/172 [00:11<00:34,  3.92it/s]\u001b[A\n",
      " 21%|██        | 36/172 [00:11<00:30,  4.48it/s]\u001b[A\n",
      " 22%|██▏       | 37/172 [00:11<00:34,  3.90it/s]\u001b[A\n",
      " 22%|██▏       | 38/172 [00:11<00:30,  4.46it/s]\u001b[A\n",
      " 23%|██▎       | 39/172 [00:12<00:33,  3.91it/s]\u001b[A\n",
      " 23%|██▎       | 40/172 [00:12<00:29,  4.47it/s]\u001b[A\n",
      " 24%|██▍       | 41/172 [00:12<00:33,  3.91it/s]\u001b[A\n",
      " 24%|██▍       | 42/172 [00:12<00:29,  4.47it/s]\u001b[A\n",
      " 25%|██▌       | 43/172 [00:13<00:32,  4.01it/s]\u001b[A\n",
      " 26%|██▌       | 44/172 [00:13<00:28,  4.54it/s]\u001b[A\n",
      " 26%|██▌       | 45/172 [00:13<00:30,  4.11it/s]\u001b[A\n",
      " 27%|██▋       | 46/172 [00:13<00:27,  4.64it/s]\u001b[A\n",
      " 27%|██▋       | 47/172 [00:13<00:29,  4.20it/s]\u001b[A\n",
      " 28%|██▊       | 48/172 [00:14<00:26,  4.72it/s]\u001b[A\n",
      " 28%|██▊       | 49/172 [00:14<00:30,  4.06it/s]\u001b[A\n",
      " 29%|██▉       | 50/172 [00:14<00:26,  4.59it/s]\u001b[A\n",
      " 30%|██▉       | 51/172 [00:14<00:30,  4.02it/s]\u001b[A\n",
      " 30%|███       | 52/172 [00:15<00:26,  4.55it/s]\u001b[A\n",
      " 31%|███       | 53/172 [00:15<00:28,  4.11it/s]\u001b[A\n",
      " 31%|███▏      | 54/172 [00:15<00:25,  4.65it/s]\u001b[A\n",
      " 32%|███▏      | 55/172 [00:15<00:27,  4.18it/s]\u001b[A\n",
      " 33%|███▎      | 56/172 [00:15<00:24,  4.71it/s]\u001b[A\n",
      " 33%|███▎      | 57/172 [00:16<00:26,  4.28it/s]\u001b[A\n",
      " 34%|███▎      | 58/172 [00:16<00:23,  4.79it/s]\u001b[A\n",
      " 34%|███▍      | 59/172 [00:16<00:26,  4.33it/s]\u001b[A\n",
      " 35%|███▍      | 60/172 [00:16<00:23,  4.84it/s]\u001b[A\n",
      " 35%|███▌      | 61/172 [00:17<00:25,  4.28it/s]\u001b[A\n",
      " 36%|███▌      | 62/172 [00:17<00:23,  4.78it/s]\u001b[A\n",
      " 37%|███▋      | 63/172 [00:17<00:25,  4.33it/s]\u001b[A\n",
      " 37%|███▋      | 64/172 [00:17<00:22,  4.84it/s]\u001b[A\n",
      " 38%|███▊      | 65/172 [00:18<00:25,  4.24it/s]\u001b[A\n",
      " 38%|███▊      | 66/172 [00:18<00:22,  4.76it/s]\u001b[A\n",
      " 39%|███▉      | 67/172 [00:18<00:24,  4.26it/s]\u001b[A\n",
      " 40%|███▉      | 68/172 [00:18<00:21,  4.77it/s]\u001b[A\n",
      " 40%|████      | 69/172 [00:18<00:23,  4.40it/s]\u001b[A\n",
      " 41%|████      | 70/172 [00:19<00:20,  4.90it/s]\u001b[A\n",
      " 41%|████▏     | 71/172 [00:19<00:23,  4.37it/s]\u001b[A\n",
      " 42%|████▏     | 72/172 [00:19<00:20,  4.86it/s]\u001b[A\n",
      " 42%|████▏     | 73/172 [00:19<00:22,  4.42it/s]\u001b[A\n",
      " 43%|████▎     | 74/172 [00:19<00:19,  4.92it/s]\u001b[A\n",
      " 44%|████▎     | 75/172 [00:20<00:21,  4.49it/s]\u001b[A\n",
      " 44%|████▍     | 76/172 [00:20<00:19,  5.02it/s]\u001b[A\n",
      " 45%|████▍     | 77/172 [00:20<00:20,  4.64it/s]\u001b[A\n",
      " 45%|████▌     | 78/172 [00:20<00:18,  5.16it/s]\u001b[A\n",
      " 46%|████▌     | 79/172 [00:20<00:20,  4.58it/s]\u001b[A\n",
      " 47%|████▋     | 80/172 [00:21<00:17,  5.13it/s]\u001b[A\n",
      " 47%|████▋     | 81/172 [00:21<00:19,  4.72it/s]\u001b[A\n",
      " 48%|████▊     | 82/172 [00:21<00:17,  5.24it/s]\u001b[A\n",
      " 48%|████▊     | 83/172 [00:21<00:18,  4.73it/s]\u001b[A\n",
      " 49%|████▉     | 84/172 [00:21<00:16,  5.26it/s]\u001b[A\n",
      " 49%|████▉     | 85/172 [00:22<00:18,  4.79it/s]\u001b[A\n",
      " 50%|█████     | 86/172 [00:22<00:16,  5.30it/s]\u001b[A\n",
      " 51%|█████     | 87/172 [00:22<00:17,  4.74it/s]\u001b[A\n",
      " 51%|█████     | 88/172 [00:22<00:15,  5.27it/s]\u001b[A\n",
      " 52%|█████▏    | 89/172 [00:22<00:17,  4.70it/s]\u001b[A\n",
      " 52%|█████▏    | 90/172 [00:23<00:15,  5.21it/s]\u001b[A\n",
      " 53%|█████▎    | 91/172 [00:23<00:17,  4.76it/s]\u001b[A\n",
      " 53%|█████▎    | 92/172 [00:23<00:15,  5.28it/s]\u001b[A\n",
      " 54%|█████▍    | 93/172 [00:23<00:16,  4.74it/s]\u001b[A\n",
      " 55%|█████▍    | 94/172 [00:23<00:14,  5.25it/s]\u001b[A\n",
      " 55%|█████▌    | 95/172 [00:24<00:16,  4.75it/s]\u001b[A\n",
      " 56%|█████▌    | 96/172 [00:24<00:14,  5.28it/s]\u001b[A\n",
      " 56%|█████▋    | 97/172 [00:24<00:15,  4.73it/s]\u001b[A\n",
      " 57%|█████▋    | 98/172 [00:24<00:14,  5.26it/s]\u001b[A\n",
      " 58%|█████▊    | 99/172 [00:24<00:15,  4.71it/s]\u001b[A\n",
      " 58%|█████▊    | 100/172 [00:25<00:13,  5.24it/s]\u001b[A\n",
      " 59%|█████▊    | 101/172 [00:25<00:15,  4.68it/s]\u001b[A\n",
      " 59%|█████▉    | 102/172 [00:25<00:13,  5.21it/s]\u001b[A\n",
      " 60%|█████▉    | 103/172 [00:25<00:14,  4.65it/s]\u001b[A\n",
      " 60%|██████    | 104/172 [00:25<00:13,  5.18it/s]\u001b[A\n",
      " 61%|██████    | 105/172 [00:26<00:14,  4.52it/s]\u001b[A\n",
      " 62%|██████▏   | 106/172 [00:26<00:13,  5.07it/s]\u001b[A\n",
      " 62%|██████▏   | 107/172 [00:26<00:13,  4.67it/s]\u001b[A\n",
      " 63%|██████▎   | 108/172 [00:26<00:12,  5.21it/s]\u001b[A\n",
      " 63%|██████▎   | 109/172 [00:27<00:13,  4.55it/s]\u001b[A\n",
      " 64%|██████▍   | 110/172 [00:27<00:12,  5.10it/s]\u001b[A\n",
      " 65%|██████▍   | 111/172 [00:27<00:13,  4.57it/s]\u001b[A\n",
      " 65%|██████▌   | 112/172 [00:27<00:11,  5.11it/s]\u001b[A\n",
      " 66%|██████▌   | 113/172 [00:27<00:13,  4.46it/s]\u001b[A\n",
      " 66%|██████▋   | 114/172 [00:28<00:11,  5.03it/s]\u001b[A\n",
      " 67%|██████▋   | 115/172 [00:28<00:12,  4.45it/s]\u001b[A\n",
      " 67%|██████▋   | 116/172 [00:28<00:11,  5.00it/s]\u001b[A\n",
      " 68%|██████▊   | 117/172 [00:28<00:12,  4.38it/s]\u001b[A\n",
      " 69%|██████▊   | 118/172 [00:28<00:10,  4.96it/s]\u001b[A\n",
      " 69%|██████▉   | 119/172 [00:29<00:11,  4.43it/s]\u001b[A\n",
      " 70%|██████▉   | 120/172 [00:29<00:10,  4.99it/s]\u001b[A\n",
      " 70%|███████   | 121/172 [00:29<00:11,  4.40it/s]\u001b[A\n",
      " 71%|███████   | 122/172 [00:29<00:10,  4.97it/s]\u001b[A\n",
      " 72%|███████▏  | 123/172 [00:30<00:11,  4.27it/s]\u001b[A\n",
      " 72%|███████▏  | 124/172 [00:30<00:09,  4.87it/s]\u001b[A\n",
      " 73%|███████▎  | 125/172 [00:31<00:19,  2.38it/s]\u001b[A\n",
      " 73%|███████▎  | 126/172 [00:31<00:15,  2.98it/s]\u001b[A\n",
      " 74%|███████▍  | 127/172 [00:31<00:14,  3.06it/s]\u001b[A\n",
      " 74%|███████▍  | 128/172 [00:31<00:11,  3.70it/s]\u001b[A\n",
      " 75%|███████▌  | 129/172 [00:32<00:12,  3.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 130/172 [00:32<00:10,  4.19it/s]\u001b[A\n",
      " 76%|███████▌  | 131/172 [00:32<00:10,  3.97it/s]\u001b[A\n",
      " 77%|███████▋  | 132/172 [00:32<00:08,  4.58it/s]\u001b[A\n",
      " 77%|███████▋  | 133/172 [00:32<00:09,  4.15it/s]\u001b[A\n",
      " 78%|███████▊  | 134/172 [00:33<00:08,  4.74it/s]\u001b[A\n",
      " 78%|███████▊  | 135/172 [00:33<00:08,  4.33it/s]\u001b[A\n",
      " 79%|███████▉  | 136/172 [00:33<00:07,  4.91it/s]\u001b[A\n",
      " 80%|███████▉  | 137/172 [00:33<00:08,  4.37it/s]\u001b[A\n",
      " 80%|████████  | 138/172 [00:33<00:06,  4.94it/s]\u001b[A\n",
      " 81%|████████  | 139/172 [00:34<00:08,  3.97it/s]\u001b[A\n",
      " 81%|████████▏ | 140/172 [00:34<00:06,  4.58it/s]\u001b[A\n",
      " 82%|████████▏ | 141/172 [00:34<00:07,  4.11it/s]\u001b[A\n",
      " 83%|████████▎ | 142/172 [00:34<00:06,  4.69it/s]\u001b[A\n",
      " 83%|████████▎ | 143/172 [00:35<00:06,  4.33it/s]\u001b[A\n",
      " 84%|████████▎ | 144/172 [00:35<00:05,  4.90it/s]\u001b[A\n",
      " 84%|████████▍ | 145/172 [00:35<00:06,  4.35it/s]\u001b[A\n",
      " 85%|████████▍ | 146/172 [00:35<00:05,  4.89it/s]\u001b[A\n",
      " 85%|████████▌ | 147/172 [00:35<00:05,  4.41it/s]\u001b[A\n",
      " 86%|████████▌ | 148/172 [00:36<00:04,  4.98it/s]\u001b[A\n",
      " 87%|████████▋ | 149/172 [00:36<00:05,  4.52it/s]\u001b[A\n",
      " 87%|████████▋ | 150/172 [00:36<00:04,  5.06it/s]\u001b[A\n",
      " 88%|████████▊ | 151/172 [00:36<00:04,  4.57it/s]\u001b[A\n",
      " 88%|████████▊ | 152/172 [00:36<00:03,  5.11it/s]\u001b[A\n",
      " 89%|████████▉ | 153/172 [00:37<00:04,  4.66it/s]\u001b[A\n",
      " 90%|████████▉ | 154/172 [00:37<00:03,  5.17it/s]\u001b[A\n",
      " 90%|█████████ | 155/172 [00:37<00:03,  4.60it/s]\u001b[A\n",
      " 91%|█████████ | 156/172 [00:37<00:03,  5.14it/s]\u001b[A\n",
      " 91%|█████████▏| 157/172 [00:37<00:03,  4.72it/s]\u001b[A\n",
      " 92%|█████████▏| 158/172 [00:38<00:02,  5.23it/s]\u001b[A\n",
      " 92%|█████████▏| 159/172 [00:38<00:02,  4.81it/s]\u001b[A\n",
      " 93%|█████████▎| 160/172 [00:38<00:02,  5.35it/s]\u001b[A\n",
      " 94%|█████████▎| 161/172 [00:38<00:02,  4.81it/s]\u001b[A\n",
      " 94%|█████████▍| 162/172 [00:38<00:01,  5.34it/s]\u001b[A\n",
      " 95%|█████████▍| 163/172 [00:39<00:01,  4.86it/s]\u001b[A\n",
      " 95%|█████████▌| 164/172 [00:39<00:01,  5.41it/s]\u001b[A\n",
      " 96%|█████████▌| 165/172 [00:39<00:01,  4.79it/s]\u001b[A\n",
      " 97%|█████████▋| 166/172 [00:39<00:01,  5.32it/s]\u001b[A\n",
      " 97%|█████████▋| 167/172 [00:39<00:01,  4.84it/s]\u001b[A\n",
      " 98%|█████████▊| 168/172 [00:40<00:00,  5.39it/s]\u001b[A\n",
      " 98%|█████████▊| 169/172 [00:40<00:00,  4.79it/s]\u001b[A\n",
      " 99%|█████████▉| 170/172 [00:40<00:00,  5.33it/s]\u001b[A\n",
      " 99%|█████████▉| 171/172 [00:40<00:00,  4.89it/s]\u001b[A\n",
      "100%|██████████| 172/172 [00:41<00:00,  4.17it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_save_path,map_location=DEVICE))\n",
    "test_loader=get_loader(test_data,batch_size=1024,train_mode=False)\n",
    "preds=validation_fn(model,test_loader,is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    169754\n",
       "2      4369\n",
       "3      1934\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label']=np.argmax(preds,axis=1)+1\n",
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.2359012e-01, 3.3287775e-02, 4.3122105e-02],\n",
       "       [9.5830983e-01, 2.4996156e-02, 1.6694093e-02],\n",
       "       [9.9851483e-01, 8.8971015e-04, 5.9537136e-04],\n",
       "       ...,\n",
       "       [9.9858665e-01, 2.2538459e-04, 1.1879839e-03],\n",
       "       [9.8011404e-01, 1.1494199e-02, 8.3917500e-03],\n",
       "       [9.7228312e-01, 2.4996301e-02, 2.7205399e-03]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from functools import partial\n",
    "\n",
    "def f1_loss(weight, y_hat, y):\n",
    "    y_hat = weight*y_hat\n",
    "    scores = f1_score(y, np.argmax(y_hat, axis=1), average=None)\n",
    "    scores = scores[0] * 0.2 + scores[1] * 0.2 + scores[2] * 0.6\n",
    "    return -scores\n",
    "def get_weights(y_hat, y):\n",
    "    size = np.unique(y).size\n",
    "    loss_partial = partial(f1_loss, y_hat=y_hat, y=y)\n",
    "    initial_weights = [1. for _ in range(size)]\n",
    "    weights_ = sp.optimize.minimize(loss_partial, initial_weights, method='Powell')\n",
    "    return weights_['x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/499 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/499 [00:01<14:53,  1.79s/it]\u001b[A\n",
      "  0%|          | 2/499 [00:01<10:44,  1.30s/it]\u001b[A\n",
      "  1%|          | 3/499 [00:02<08:26,  1.02s/it]\u001b[A\n",
      "  1%|          | 4/499 [00:02<06:13,  1.32it/s]\u001b[A\n",
      "  1%|          | 5/499 [00:02<05:11,  1.58it/s]\u001b[A\n",
      "  1%|          | 6/499 [00:02<03:57,  2.07it/s]\u001b[A\n",
      "  1%|▏         | 7/499 [00:03<03:38,  2.25it/s]\u001b[A\n",
      "  2%|▏         | 8/499 [00:03<02:53,  2.83it/s]\u001b[A\n",
      "  2%|▏         | 9/499 [00:03<02:50,  2.87it/s]\u001b[A\n",
      "  2%|▏         | 10/499 [00:03<02:20,  3.48it/s]\u001b[A\n",
      "  2%|▏         | 11/499 [00:04<02:24,  3.37it/s]\u001b[A\n",
      "  2%|▏         | 12/499 [00:04<02:01,  3.99it/s]\u001b[A\n",
      "  3%|▎         | 13/499 [00:04<02:10,  3.71it/s]\u001b[A\n",
      "  3%|▎         | 14/499 [00:04<01:51,  4.36it/s]\u001b[A\n",
      "  3%|▎         | 15/499 [00:05<02:11,  3.69it/s]\u001b[A\n",
      "  3%|▎         | 16/499 [00:05<01:51,  4.35it/s]\u001b[A\n",
      "  3%|▎         | 17/499 [00:05<02:03,  3.90it/s]\u001b[A\n",
      "  4%|▎         | 18/499 [00:05<01:45,  4.55it/s]\u001b[A\n",
      "  4%|▍         | 19/499 [00:06<01:55,  4.14it/s]\u001b[A\n",
      "  4%|▍         | 20/499 [00:06<01:40,  4.76it/s]\u001b[A\n",
      "  4%|▍         | 21/499 [00:06<01:51,  4.27it/s]\u001b[A\n",
      "  4%|▍         | 22/499 [00:06<01:37,  4.89it/s]\u001b[A\n",
      "  5%|▍         | 23/499 [00:06<01:48,  4.39it/s]\u001b[A\n",
      "  5%|▍         | 24/499 [00:07<01:35,  4.99it/s]\u001b[A\n",
      "  5%|▌         | 25/499 [00:07<01:47,  4.41it/s]\u001b[A\n",
      "  5%|▌         | 26/499 [00:07<01:34,  4.98it/s]\u001b[A\n",
      "  5%|▌         | 27/499 [00:07<01:45,  4.47it/s]\u001b[A\n",
      "  6%|▌         | 28/499 [00:07<01:33,  5.01it/s]\u001b[A\n",
      "  6%|▌         | 29/499 [00:08<01:45,  4.47it/s]\u001b[A\n",
      "  6%|▌         | 30/499 [00:08<01:33,  5.01it/s]\u001b[A\n",
      "  6%|▌         | 31/499 [00:08<01:42,  4.58it/s]\u001b[A\n",
      "  6%|▋         | 32/499 [00:08<01:31,  5.11it/s]\u001b[A\n",
      "  7%|▋         | 33/499 [00:08<01:41,  4.58it/s]\u001b[A\n",
      "  7%|▋         | 34/499 [00:09<01:30,  5.12it/s]\u001b[A\n",
      "  7%|▋         | 35/499 [00:09<01:40,  4.63it/s]\u001b[A\n",
      "  7%|▋         | 36/499 [00:09<01:29,  5.16it/s]\u001b[A\n",
      "  7%|▋         | 37/499 [00:09<01:39,  4.66it/s]\u001b[A\n",
      "  8%|▊         | 38/499 [00:09<01:28,  5.19it/s]\u001b[A\n",
      "  8%|▊         | 39/499 [00:10<01:37,  4.73it/s]\u001b[A\n",
      "  8%|▊         | 40/499 [00:10<01:27,  5.25it/s]\u001b[A\n",
      "  8%|▊         | 41/499 [00:10<01:36,  4.74it/s]\u001b[A\n",
      "  8%|▊         | 42/499 [00:10<01:26,  5.26it/s]\u001b[A\n",
      "  9%|▊         | 43/499 [00:10<01:34,  4.82it/s]\u001b[A\n",
      "  9%|▉         | 44/499 [00:11<01:25,  5.30it/s]\u001b[A\n",
      "  9%|▉         | 45/499 [00:11<01:33,  4.85it/s]\u001b[A\n",
      "  9%|▉         | 46/499 [00:11<01:24,  5.35it/s]\u001b[A\n",
      "  9%|▉         | 47/499 [00:11<01:32,  4.89it/s]\u001b[A\n",
      " 10%|▉         | 48/499 [00:11<01:24,  5.36it/s]\u001b[A\n",
      " 10%|▉         | 49/499 [00:12<01:32,  4.89it/s]\u001b[A\n",
      " 10%|█         | 50/499 [00:12<01:23,  5.38it/s]\u001b[A\n",
      " 10%|█         | 51/499 [00:12<01:31,  4.89it/s]\u001b[A\n",
      " 10%|█         | 52/499 [00:12<01:24,  5.29it/s]\u001b[A\n",
      " 11%|█         | 53/499 [00:12<01:30,  4.93it/s]\u001b[A\n",
      " 11%|█         | 54/499 [00:13<01:26,  5.17it/s]\u001b[A\n",
      " 11%|█         | 55/499 [00:13<01:28,  4.99it/s]\u001b[A\n",
      " 11%|█         | 56/499 [00:13<01:27,  5.06it/s]\u001b[A\n",
      " 11%|█▏        | 57/499 [00:13<01:27,  5.07it/s]\u001b[A\n",
      " 12%|█▏        | 58/499 [00:13<01:27,  5.02it/s]\u001b[A\n",
      " 12%|█▏        | 59/499 [00:14<01:26,  5.11it/s]\u001b[A\n",
      " 12%|█▏        | 60/499 [00:14<01:30,  4.83it/s]\u001b[A\n",
      " 12%|█▏        | 61/499 [00:14<01:22,  5.28it/s]\u001b[A\n",
      " 12%|█▏        | 62/499 [00:14<01:30,  4.83it/s]\u001b[A\n",
      " 13%|█▎        | 63/499 [00:14<01:22,  5.26it/s]\u001b[A\n",
      " 13%|█▎        | 64/499 [00:15<01:30,  4.80it/s]\u001b[A\n",
      " 13%|█▎        | 65/499 [00:15<01:22,  5.29it/s]\u001b[A\n",
      " 13%|█▎        | 66/499 [00:15<01:30,  4.79it/s]\u001b[A\n",
      " 13%|█▎        | 67/499 [00:15<01:22,  5.26it/s]\u001b[A\n",
      " 14%|█▎        | 68/499 [00:15<01:30,  4.74it/s]\u001b[A\n",
      " 14%|█▍        | 69/499 [00:16<01:22,  5.23it/s]\u001b[A\n",
      " 14%|█▍        | 70/499 [00:16<01:32,  4.65it/s]\u001b[A\n",
      " 14%|█▍        | 71/499 [00:16<01:23,  5.13it/s]\u001b[A\n",
      " 14%|█▍        | 72/499 [00:16<01:31,  4.66it/s]\u001b[A\n",
      " 15%|█▍        | 73/499 [00:16<01:22,  5.16it/s]\u001b[A\n",
      " 15%|█▍        | 74/499 [00:17<01:31,  4.63it/s]\u001b[A\n",
      " 15%|█▌        | 75/499 [00:17<01:22,  5.12it/s]\u001b[A\n",
      " 15%|█▌        | 76/499 [00:17<01:30,  4.65it/s]\u001b[A\n",
      " 15%|█▌        | 77/499 [00:17<01:21,  5.16it/s]\u001b[A\n",
      " 16%|█▌        | 78/499 [00:17<01:27,  4.79it/s]\u001b[A\n",
      " 16%|█▌        | 79/499 [00:18<01:19,  5.28it/s]\u001b[A\n",
      " 16%|█▌        | 80/499 [00:18<01:27,  4.76it/s]\u001b[A\n",
      " 16%|█▌        | 81/499 [00:18<01:18,  5.30it/s]\u001b[A\n",
      " 16%|█▋        | 82/499 [00:18<01:28,  4.74it/s]\u001b[A\n",
      " 17%|█▋        | 83/499 [00:18<01:19,  5.26it/s]\u001b[A\n",
      " 17%|█▋        | 84/499 [00:19<01:28,  4.68it/s]\u001b[A\n",
      " 17%|█▋        | 85/499 [00:19<01:19,  5.23it/s]\u001b[A\n",
      " 17%|█▋        | 86/499 [00:19<01:30,  4.57it/s]\u001b[A\n",
      " 17%|█▋        | 87/499 [00:19<01:20,  5.12it/s]\u001b[A\n",
      " 18%|█▊        | 88/499 [00:20<01:35,  4.31it/s]\u001b[A\n",
      " 18%|█▊        | 89/499 [00:20<01:23,  4.92it/s]\u001b[A\n",
      " 18%|█▊        | 90/499 [00:20<01:32,  4.42it/s]\u001b[A\n",
      " 18%|█▊        | 91/499 [00:20<01:21,  5.03it/s]\u001b[A\n",
      " 18%|█▊        | 92/499 [00:20<01:33,  4.36it/s]\u001b[A\n",
      " 19%|█▊        | 93/499 [00:21<01:21,  4.97it/s]\u001b[A\n",
      " 19%|█▉        | 94/499 [00:21<01:34,  4.27it/s]\u001b[A\n",
      " 19%|█▉        | 95/499 [00:21<01:22,  4.89it/s]\u001b[A\n",
      " 19%|█▉        | 96/499 [00:21<01:35,  4.24it/s]\u001b[A\n",
      " 19%|█▉        | 97/499 [00:21<01:22,  4.86it/s]\u001b[A\n",
      " 20%|█▉        | 98/499 [00:22<01:37,  4.09it/s]\u001b[A\n",
      " 20%|█▉        | 99/499 [00:22<01:25,  4.68it/s]\u001b[A\n",
      " 20%|██        | 100/499 [00:22<01:38,  4.04it/s]\u001b[A\n",
      " 20%|██        | 101/499 [00:22<01:25,  4.63it/s]\u001b[A\n",
      " 20%|██        | 102/499 [00:23<01:36,  4.10it/s]\u001b[A\n",
      " 21%|██        | 103/499 [00:23<01:24,  4.71it/s]\u001b[A\n",
      " 21%|██        | 104/499 [00:23<01:34,  4.16it/s]\u001b[A\n",
      " 21%|██        | 105/499 [00:23<01:29,  4.42it/s]\u001b[A\n",
      " 21%|██        | 106/499 [00:24<02:14,  2.93it/s]\u001b[A\n",
      " 21%|██▏       | 107/499 [00:24<01:50,  3.56it/s]\u001b[A\n",
      " 22%|██▏       | 108/499 [00:24<01:51,  3.52it/s]\u001b[A\n",
      " 22%|██▏       | 109/499 [00:25<01:33,  4.16it/s]\u001b[A\n",
      " 22%|██▏       | 110/499 [00:25<01:48,  3.59it/s]\u001b[A\n",
      " 22%|██▏       | 111/499 [00:25<01:32,  4.22it/s]\u001b[A\n",
      " 22%|██▏       | 112/499 [00:25<01:38,  3.91it/s]\u001b[A\n",
      " 23%|██▎       | 113/499 [00:25<01:25,  4.51it/s]\u001b[A\n",
      " 23%|██▎       | 114/499 [00:26<01:32,  4.18it/s]\u001b[A\n",
      " 23%|██▎       | 115/499 [00:26<01:20,  4.80it/s]\u001b[A\n",
      " 23%|██▎       | 116/499 [00:26<01:27,  4.37it/s]\u001b[A\n",
      " 23%|██▎       | 117/499 [00:26<01:17,  4.95it/s]\u001b[A\n",
      " 24%|██▎       | 118/499 [00:27<01:25,  4.48it/s]\u001b[A\n",
      " 24%|██▍       | 119/499 [00:27<01:14,  5.08it/s]\u001b[A\n",
      " 24%|██▍       | 120/499 [00:27<01:23,  4.55it/s]\u001b[A\n",
      " 24%|██▍       | 121/499 [00:27<01:13,  5.12it/s]\u001b[A\n",
      " 24%|██▍       | 122/499 [00:27<01:21,  4.61it/s]\u001b[A\n",
      " 25%|██▍       | 123/499 [00:28<01:12,  5.20it/s]\u001b[A\n",
      " 25%|██▍       | 124/499 [00:28<01:21,  4.61it/s]\u001b[A\n",
      " 25%|██▌       | 125/499 [00:28<01:12,  5.17it/s]\u001b[A\n",
      " 25%|██▌       | 126/499 [00:28<01:20,  4.65it/s]\u001b[A\n",
      " 25%|██▌       | 127/499 [00:28<01:11,  5.23it/s]\u001b[A\n",
      " 26%|██▌       | 128/499 [00:29<01:20,  4.59it/s]\u001b[A\n",
      " 26%|██▌       | 129/499 [00:29<01:11,  5.15it/s]\u001b[A\n",
      " 26%|██▌       | 130/499 [00:29<01:19,  4.62it/s]\u001b[A\n",
      " 26%|██▋       | 131/499 [00:29<01:10,  5.20it/s]\u001b[A\n",
      " 26%|██▋       | 132/499 [00:29<01:18,  4.68it/s]\u001b[A\n",
      " 27%|██▋       | 133/499 [00:30<01:09,  5.24it/s]\u001b[A\n",
      " 27%|██▋       | 134/499 [00:30<01:16,  4.75it/s]\u001b[A\n",
      " 27%|██▋       | 135/499 [00:30<01:08,  5.31it/s]\u001b[A\n",
      " 27%|██▋       | 136/499 [00:30<01:15,  4.80it/s]\u001b[A\n",
      " 27%|██▋       | 137/499 [00:30<01:07,  5.35it/s]\u001b[A\n",
      " 28%|██▊       | 138/499 [00:31<01:14,  4.82it/s]\u001b[A\n",
      " 28%|██▊       | 139/499 [00:31<01:07,  5.37it/s]\u001b[A\n",
      " 28%|██▊       | 140/499 [00:31<01:14,  4.83it/s]\u001b[A\n",
      " 28%|██▊       | 141/499 [00:31<01:06,  5.38it/s]\u001b[A\n",
      " 28%|██▊       | 142/499 [00:31<01:13,  4.88it/s]\u001b[A\n",
      " 29%|██▊       | 143/499 [00:32<01:05,  5.43it/s]\u001b[A\n",
      " 29%|██▉       | 144/499 [00:32<01:12,  4.88it/s]\u001b[A\n",
      " 29%|██▉       | 145/499 [00:32<01:05,  5.42it/s]\u001b[A\n",
      " 29%|██▉       | 146/499 [00:32<01:12,  4.89it/s]\u001b[A\n",
      " 29%|██▉       | 147/499 [00:32<01:04,  5.43it/s]\u001b[A\n",
      " 30%|██▉       | 148/499 [00:33<01:11,  4.90it/s]\u001b[A\n",
      " 30%|██▉       | 149/499 [00:33<01:04,  5.44it/s]\u001b[A\n",
      " 30%|███       | 150/499 [00:33<01:10,  4.93it/s]\u001b[A\n",
      " 30%|███       | 151/499 [00:33<01:03,  5.47it/s]\u001b[A\n",
      " 30%|███       | 152/499 [00:33<01:10,  4.92it/s]\u001b[A\n",
      " 31%|███       | 153/499 [00:33<01:03,  5.46it/s]\u001b[A\n",
      " 31%|███       | 154/499 [00:34<01:10,  4.89it/s]\u001b[A\n",
      " 31%|███       | 155/499 [00:34<01:03,  5.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 156/499 [00:34<01:08,  5.01it/s]\u001b[A\n",
      " 31%|███▏      | 157/499 [00:34<01:01,  5.56it/s]\u001b[A\n",
      " 32%|███▏      | 158/499 [00:34<01:07,  5.03it/s]\u001b[A\n",
      " 32%|███▏      | 159/499 [00:35<01:01,  5.56it/s]\u001b[A\n",
      " 32%|███▏      | 160/499 [00:35<01:07,  5.00it/s]\u001b[A\n",
      " 32%|███▏      | 161/499 [00:35<01:00,  5.55it/s]\u001b[A\n",
      " 32%|███▏      | 162/499 [00:35<01:08,  4.95it/s]\u001b[A\n",
      " 33%|███▎      | 163/499 [00:35<01:01,  5.49it/s]\u001b[A\n",
      " 33%|███▎      | 164/499 [00:36<01:06,  5.02it/s]\u001b[A\n",
      " 33%|███▎      | 165/499 [00:36<01:00,  5.56it/s]\u001b[A\n",
      " 33%|███▎      | 166/499 [00:36<01:06,  5.03it/s]\u001b[A\n",
      " 33%|███▎      | 167/499 [00:36<00:59,  5.55it/s]\u001b[A\n",
      " 34%|███▎      | 168/499 [00:36<01:05,  5.08it/s]\u001b[A\n",
      " 34%|███▍      | 169/499 [00:36<00:58,  5.61it/s]\u001b[A\n",
      " 34%|███▍      | 170/499 [00:37<01:04,  5.06it/s]\u001b[A\n",
      " 34%|███▍      | 171/499 [00:37<00:58,  5.58it/s]\u001b[A\n",
      " 34%|███▍      | 172/499 [00:37<01:04,  5.08it/s]\u001b[A\n",
      " 35%|███▍      | 173/499 [00:37<00:58,  5.61it/s]\u001b[A\n",
      " 35%|███▍      | 174/499 [00:37<01:03,  5.09it/s]\u001b[A\n",
      " 35%|███▌      | 175/499 [00:38<00:57,  5.60it/s]\u001b[A\n",
      " 35%|███▌      | 176/499 [00:38<01:04,  5.00it/s]\u001b[A\n",
      " 35%|███▌      | 177/499 [00:38<00:58,  5.55it/s]\u001b[A\n",
      " 36%|███▌      | 178/499 [00:38<01:03,  5.06it/s]\u001b[A\n",
      " 36%|███▌      | 179/499 [00:38<00:57,  5.58it/s]\u001b[A\n",
      " 36%|███▌      | 180/499 [00:39<01:03,  5.00it/s]\u001b[A\n",
      " 36%|███▋      | 181/499 [00:39<00:57,  5.55it/s]\u001b[A\n",
      " 36%|███▋      | 182/499 [00:39<01:03,  4.97it/s]\u001b[A\n",
      " 37%|███▋      | 183/499 [00:39<00:57,  5.52it/s]\u001b[A\n",
      " 37%|███▋      | 184/499 [00:39<01:03,  4.96it/s]\u001b[A\n",
      " 37%|███▋      | 185/499 [00:40<00:56,  5.51it/s]\u001b[A\n",
      " 37%|███▋      | 186/499 [00:40<01:03,  4.95it/s]\u001b[A\n",
      " 37%|███▋      | 187/499 [00:40<00:56,  5.50it/s]\u001b[A\n",
      " 38%|███▊      | 188/499 [00:40<01:02,  4.97it/s]\u001b[A\n",
      " 38%|███▊      | 189/499 [00:40<00:56,  5.51it/s]\u001b[A\n",
      " 38%|███▊      | 190/499 [00:41<01:02,  4.94it/s]\u001b[A\n",
      " 38%|███▊      | 191/499 [00:41<00:56,  5.48it/s]\u001b[A\n",
      " 38%|███▊      | 192/499 [00:41<01:02,  4.90it/s]\u001b[A\n",
      " 39%|███▊      | 193/499 [00:41<00:56,  5.46it/s]\u001b[A\n",
      " 39%|███▉      | 194/499 [00:41<01:03,  4.82it/s]\u001b[A\n",
      " 39%|███▉      | 195/499 [00:41<00:56,  5.39it/s]\u001b[A\n",
      " 39%|███▉      | 196/499 [00:42<01:03,  4.79it/s]\u001b[A\n",
      " 39%|███▉      | 197/499 [00:42<00:56,  5.37it/s]\u001b[A\n",
      " 40%|███▉      | 198/499 [00:42<01:03,  4.72it/s]\u001b[A\n",
      " 40%|███▉      | 199/499 [00:42<00:56,  5.30it/s]\u001b[A\n",
      " 40%|████      | 200/499 [00:43<01:03,  4.69it/s]\u001b[A\n",
      " 40%|████      | 201/499 [00:43<00:56,  5.27it/s]\u001b[A\n",
      " 40%|████      | 202/499 [00:43<01:04,  4.58it/s]\u001b[A\n",
      " 41%|████      | 203/499 [00:43<00:57,  5.17it/s]\u001b[A\n",
      " 41%|████      | 204/499 [00:43<01:04,  4.58it/s]\u001b[A\n",
      " 41%|████      | 205/499 [00:43<00:56,  5.17it/s]\u001b[A\n",
      " 41%|████▏     | 206/499 [00:44<01:04,  4.54it/s]\u001b[A\n",
      " 41%|████▏     | 207/499 [00:44<00:56,  5.14it/s]\u001b[A\n",
      " 42%|████▏     | 208/499 [00:44<01:04,  4.53it/s]\u001b[A\n",
      " 42%|████▏     | 209/499 [00:44<00:56,  5.13it/s]\u001b[A\n",
      " 42%|████▏     | 210/499 [00:45<01:04,  4.48it/s]\u001b[A\n",
      " 42%|████▏     | 211/499 [00:45<00:56,  5.09it/s]\u001b[A\n",
      " 42%|████▏     | 212/499 [00:45<01:03,  4.50it/s]\u001b[A\n",
      " 43%|████▎     | 213/499 [00:45<00:56,  5.10it/s]\u001b[A\n",
      " 43%|████▎     | 214/499 [00:46<01:26,  3.29it/s]\u001b[A\n",
      " 43%|████▎     | 215/499 [00:46<01:11,  3.95it/s]\u001b[A\n",
      " 43%|████▎     | 216/499 [00:46<01:14,  3.79it/s]\u001b[A\n",
      " 43%|████▎     | 217/499 [00:46<01:03,  4.44it/s]\u001b[A\n",
      " 44%|████▎     | 218/499 [00:47<01:09,  4.02it/s]\u001b[A\n",
      " 44%|████▍     | 219/499 [00:47<01:00,  4.66it/s]\u001b[A\n",
      " 44%|████▍     | 220/499 [00:47<01:06,  4.22it/s]\u001b[A\n",
      " 44%|████▍     | 221/499 [00:47<00:57,  4.87it/s]\u001b[A\n",
      " 44%|████▍     | 222/499 [00:47<01:04,  4.29it/s]\u001b[A\n",
      " 45%|████▍     | 223/499 [00:48<00:55,  4.93it/s]\u001b[A\n",
      " 45%|████▍     | 224/499 [00:48<01:02,  4.37it/s]\u001b[A\n",
      " 45%|████▌     | 225/499 [00:48<00:54,  4.99it/s]\u001b[A\n",
      " 45%|████▌     | 226/499 [00:48<01:01,  4.43it/s]\u001b[A\n",
      " 45%|████▌     | 227/499 [00:48<00:53,  5.06it/s]\u001b[A\n",
      " 46%|████▌     | 228/499 [00:49<01:00,  4.50it/s]\u001b[A\n",
      " 46%|████▌     | 229/499 [00:49<00:52,  5.10it/s]\u001b[A\n",
      " 46%|████▌     | 230/499 [00:49<00:58,  4.57it/s]\u001b[A\n",
      " 46%|████▋     | 231/499 [00:49<00:51,  5.19it/s]\u001b[A\n",
      " 46%|████▋     | 232/499 [00:50<00:58,  4.54it/s]\u001b[A\n",
      " 47%|████▋     | 233/499 [00:50<00:51,  5.13it/s]\u001b[A\n",
      " 47%|████▋     | 234/499 [00:50<00:57,  4.63it/s]\u001b[A\n",
      " 47%|████▋     | 235/499 [00:50<00:50,  5.23it/s]\u001b[A\n",
      " 47%|████▋     | 236/499 [00:50<00:56,  4.67it/s]\u001b[A\n",
      " 47%|████▋     | 237/499 [00:50<00:49,  5.24it/s]\u001b[A\n",
      " 48%|████▊     | 238/499 [00:51<00:59,  4.38it/s]\u001b[A\n",
      " 48%|████▊     | 239/499 [00:51<00:52,  5.00it/s]\u001b[A\n",
      " 48%|████▊     | 240/499 [00:51<00:57,  4.49it/s]\u001b[A\n",
      " 48%|████▊     | 241/499 [00:51<00:50,  5.08it/s]\u001b[A\n",
      " 48%|████▊     | 242/499 [00:52<00:55,  4.62it/s]\u001b[A\n",
      " 49%|████▊     | 243/499 [00:52<00:49,  5.19it/s]\u001b[A\n",
      " 49%|████▉     | 244/499 [00:52<00:55,  4.61it/s]\u001b[A\n",
      " 49%|████▉     | 245/499 [00:52<00:48,  5.19it/s]\u001b[A\n",
      " 49%|████▉     | 246/499 [00:52<00:53,  4.72it/s]\u001b[A\n",
      " 49%|████▉     | 247/499 [00:53<00:47,  5.31it/s]\u001b[A\n",
      " 50%|████▉     | 248/499 [00:53<00:52,  4.76it/s]\u001b[A\n",
      " 50%|████▉     | 249/499 [00:53<00:46,  5.32it/s]\u001b[A\n",
      " 50%|█████     | 250/499 [00:53<00:51,  4.81it/s]\u001b[A\n",
      " 50%|█████     | 251/499 [00:53<00:46,  5.38it/s]\u001b[A\n",
      " 51%|█████     | 252/499 [00:54<00:52,  4.75it/s]\u001b[A\n",
      " 51%|█████     | 253/499 [00:54<00:47,  5.20it/s]\u001b[A\n",
      " 51%|█████     | 254/499 [00:54<00:51,  4.76it/s]\u001b[A\n",
      " 51%|█████     | 255/499 [00:54<00:46,  5.29it/s]\u001b[A\n",
      " 51%|█████▏    | 256/499 [00:54<00:50,  4.84it/s]\u001b[A\n",
      " 52%|█████▏    | 257/499 [00:54<00:44,  5.41it/s]\u001b[A\n",
      " 52%|█████▏    | 258/499 [00:55<00:49,  4.89it/s]\u001b[A\n",
      " 52%|█████▏    | 259/499 [00:55<00:44,  5.43it/s]\u001b[A\n",
      " 52%|█████▏    | 260/499 [00:55<00:48,  4.94it/s]\u001b[A\n",
      " 52%|█████▏    | 261/499 [00:55<00:43,  5.50it/s]\u001b[A\n",
      " 53%|█████▎    | 262/499 [00:56<00:47,  4.96it/s]\u001b[A\n",
      " 53%|█████▎    | 263/499 [00:56<00:43,  5.48it/s]\u001b[A\n",
      " 53%|█████▎    | 264/499 [00:56<00:47,  4.98it/s]\u001b[A\n",
      " 53%|█████▎    | 265/499 [00:56<00:42,  5.53it/s]\u001b[A\n",
      " 53%|█████▎    | 266/499 [00:56<00:46,  5.02it/s]\u001b[A\n",
      " 54%|█████▎    | 267/499 [00:56<00:41,  5.56it/s]\u001b[A\n",
      " 54%|█████▎    | 268/499 [00:57<00:45,  5.04it/s]\u001b[A\n",
      " 54%|█████▍    | 269/499 [00:57<00:41,  5.60it/s]\u001b[A\n",
      " 54%|█████▍    | 270/499 [00:57<00:45,  5.03it/s]\u001b[A\n",
      " 54%|█████▍    | 271/499 [00:57<00:40,  5.57it/s]\u001b[A\n",
      " 55%|█████▍    | 272/499 [00:57<00:44,  5.07it/s]\u001b[A\n",
      " 55%|█████▍    | 273/499 [00:58<00:40,  5.62it/s]\u001b[A\n",
      " 55%|█████▍    | 274/499 [00:58<00:44,  5.08it/s]\u001b[A\n",
      " 55%|█████▌    | 275/499 [00:58<00:39,  5.61it/s]\u001b[A\n",
      " 55%|█████▌    | 276/499 [00:58<00:43,  5.08it/s]\u001b[A\n",
      " 56%|█████▌    | 277/499 [00:58<00:39,  5.63it/s]\u001b[A\n",
      " 56%|█████▌    | 278/499 [00:59<00:43,  5.06it/s]\u001b[A\n",
      " 56%|█████▌    | 279/499 [00:59<00:39,  5.54it/s]\u001b[A\n",
      " 56%|█████▌    | 280/499 [00:59<00:43,  5.03it/s]\u001b[A\n",
      " 56%|█████▋    | 281/499 [00:59<00:39,  5.46it/s]\u001b[A\n",
      " 57%|█████▋    | 282/499 [00:59<00:43,  5.03it/s]\u001b[A\n",
      " 57%|█████▋    | 283/499 [00:59<00:39,  5.41it/s]\u001b[A\n",
      " 57%|█████▋    | 284/499 [01:00<00:42,  5.10it/s]\u001b[A\n",
      " 57%|█████▋    | 285/499 [01:00<00:39,  5.43it/s]\u001b[A\n",
      " 57%|█████▋    | 286/499 [01:00<00:41,  5.11it/s]\u001b[A\n",
      " 58%|█████▊    | 287/499 [01:00<00:39,  5.42it/s]\u001b[A\n",
      " 58%|█████▊    | 288/499 [01:00<00:40,  5.17it/s]\u001b[A\n",
      " 58%|█████▊    | 289/499 [01:01<00:38,  5.41it/s]\u001b[A\n",
      " 58%|█████▊    | 290/499 [01:01<00:40,  5.20it/s]\u001b[A\n",
      " 58%|█████▊    | 291/499 [01:01<00:38,  5.36it/s]\u001b[A\n",
      " 59%|█████▊    | 292/499 [01:01<00:39,  5.19it/s]\u001b[A\n",
      " 59%|█████▊    | 293/499 [01:01<00:39,  5.26it/s]\u001b[A\n",
      " 59%|█████▉    | 294/499 [01:02<00:41,  4.99it/s]\u001b[A\n",
      " 59%|█████▉    | 295/499 [01:02<00:39,  5.17it/s]\u001b[A\n",
      " 59%|█████▉    | 296/499 [01:02<00:40,  5.05it/s]\u001b[A\n",
      " 60%|█████▉    | 297/499 [01:02<00:39,  5.16it/s]\u001b[A\n",
      " 60%|█████▉    | 298/499 [01:02<00:39,  5.15it/s]\u001b[A\n",
      " 60%|█████▉    | 299/499 [01:03<00:38,  5.14it/s]\u001b[A\n",
      " 60%|██████    | 300/499 [01:03<00:38,  5.11it/s]\u001b[A\n",
      " 60%|██████    | 301/499 [01:03<00:38,  5.18it/s]\u001b[A\n",
      " 61%|██████    | 302/499 [01:03<00:37,  5.30it/s]\u001b[A\n",
      " 61%|██████    | 303/499 [01:03<00:37,  5.24it/s]\u001b[A\n",
      " 61%|██████    | 304/499 [01:03<00:36,  5.36it/s]\u001b[A\n",
      " 61%|██████    | 305/499 [01:04<00:37,  5.11it/s]\u001b[A\n",
      " 61%|██████▏   | 306/499 [01:04<00:37,  5.19it/s]\u001b[A\n",
      " 62%|██████▏   | 307/499 [01:04<00:39,  4.85it/s]\u001b[A\n",
      " 62%|██████▏   | 308/499 [01:04<00:38,  4.98it/s]\u001b[A\n",
      " 62%|██████▏   | 309/499 [01:05<00:41,  4.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/499 [01:05<00:37,  5.00it/s]\u001b[A\n",
      " 62%|██████▏   | 311/499 [01:05<00:42,  4.45it/s]\u001b[A\n",
      " 63%|██████▎   | 312/499 [01:05<00:37,  4.99it/s]\u001b[A\n",
      " 63%|██████▎   | 313/499 [01:05<00:40,  4.60it/s]\u001b[A\n",
      " 63%|██████▎   | 314/499 [01:06<00:36,  5.11it/s]\u001b[A\n",
      " 63%|██████▎   | 315/499 [01:06<00:41,  4.39it/s]\u001b[A\n",
      " 63%|██████▎   | 316/499 [01:06<00:37,  4.93it/s]\u001b[A\n",
      " 64%|██████▎   | 317/499 [01:06<00:40,  4.49it/s]\u001b[A\n",
      " 64%|██████▎   | 318/499 [01:06<00:36,  5.02it/s]\u001b[A\n",
      " 64%|██████▍   | 319/499 [01:07<00:39,  4.61it/s]\u001b[A\n",
      " 64%|██████▍   | 320/499 [01:07<00:35,  5.08it/s]\u001b[A\n",
      " 64%|██████▍   | 321/499 [01:07<00:48,  3.69it/s]\u001b[A\n",
      " 65%|██████▍   | 322/499 [01:07<00:41,  4.26it/s]\u001b[A\n",
      " 65%|██████▍   | 323/499 [01:08<00:42,  4.11it/s]\u001b[A\n",
      " 65%|██████▍   | 324/499 [01:08<00:37,  4.63it/s]\u001b[A\n",
      " 65%|██████▌   | 325/499 [01:08<00:39,  4.43it/s]\u001b[A\n",
      " 65%|██████▌   | 326/499 [01:08<00:35,  4.91it/s]\u001b[A\n",
      " 66%|██████▌   | 327/499 [01:08<00:37,  4.58it/s]\u001b[A\n",
      " 66%|██████▌   | 328/499 [01:09<00:33,  5.09it/s]\u001b[A\n",
      " 66%|██████▌   | 329/499 [01:09<00:35,  4.81it/s]\u001b[A\n",
      " 66%|██████▌   | 330/499 [01:09<00:31,  5.29it/s]\u001b[A\n",
      " 66%|██████▋   | 331/499 [01:09<00:35,  4.79it/s]\u001b[A\n",
      " 67%|██████▋   | 332/499 [01:09<00:31,  5.26it/s]\u001b[A\n",
      " 67%|██████▋   | 333/499 [01:10<00:34,  4.81it/s]\u001b[A\n",
      " 67%|██████▋   | 334/499 [01:10<00:31,  5.28it/s]\u001b[A\n",
      " 67%|██████▋   | 335/499 [01:10<00:34,  4.80it/s]\u001b[A\n",
      " 67%|██████▋   | 336/499 [01:10<00:30,  5.29it/s]\u001b[A\n",
      " 68%|██████▊   | 337/499 [01:10<00:33,  4.82it/s]\u001b[A\n",
      " 68%|██████▊   | 338/499 [01:11<00:30,  5.29it/s]\u001b[A\n",
      " 68%|██████▊   | 339/499 [01:11<00:33,  4.81it/s]\u001b[A\n",
      " 68%|██████▊   | 340/499 [01:11<00:30,  5.29it/s]\u001b[A\n",
      " 68%|██████▊   | 341/499 [01:11<00:33,  4.75it/s]\u001b[A\n",
      " 69%|██████▊   | 342/499 [01:11<00:30,  5.23it/s]\u001b[A\n",
      " 69%|██████▊   | 343/499 [01:12<00:32,  4.79it/s]\u001b[A\n",
      " 69%|██████▉   | 344/499 [01:12<00:29,  5.27it/s]\u001b[A\n",
      " 69%|██████▉   | 345/499 [01:12<00:32,  4.76it/s]\u001b[A\n",
      " 69%|██████▉   | 346/499 [01:12<00:29,  5.21it/s]\u001b[A\n",
      " 70%|██████▉   | 347/499 [01:12<00:31,  4.79it/s]\u001b[A\n",
      " 70%|██████▉   | 348/499 [01:13<00:28,  5.21it/s]\u001b[A\n",
      " 70%|██████▉   | 349/499 [01:13<00:31,  4.82it/s]\u001b[A\n",
      " 70%|███████   | 350/499 [01:13<00:28,  5.30it/s]\u001b[A\n",
      " 70%|███████   | 351/499 [01:13<00:30,  4.84it/s]\u001b[A\n",
      " 71%|███████   | 352/499 [01:13<00:27,  5.29it/s]\u001b[A\n",
      " 71%|███████   | 353/499 [01:14<00:29,  4.94it/s]\u001b[A\n",
      " 71%|███████   | 354/499 [01:14<00:26,  5.43it/s]\u001b[A\n",
      " 71%|███████   | 355/499 [01:14<00:28,  4.97it/s]\u001b[A\n",
      " 71%|███████▏  | 356/499 [01:14<00:26,  5.44it/s]\u001b[A\n",
      " 72%|███████▏  | 357/499 [01:14<00:29,  4.88it/s]\u001b[A\n",
      " 72%|███████▏  | 358/499 [01:15<00:26,  5.40it/s]\u001b[A\n",
      " 72%|███████▏  | 359/499 [01:15<00:27,  5.00it/s]\u001b[A\n",
      " 72%|███████▏  | 360/499 [01:15<00:25,  5.38it/s]\u001b[A\n",
      " 72%|███████▏  | 361/499 [01:15<00:27,  5.09it/s]\u001b[A\n",
      " 73%|███████▎  | 362/499 [01:15<00:26,  5.25it/s]\u001b[A\n",
      " 73%|███████▎  | 363/499 [01:16<00:26,  5.12it/s]\u001b[A\n",
      " 73%|███████▎  | 364/499 [01:16<00:26,  5.15it/s]\u001b[A\n",
      " 73%|███████▎  | 365/499 [01:16<00:25,  5.23it/s]\u001b[A\n",
      " 73%|███████▎  | 366/499 [01:16<00:26,  4.94it/s]\u001b[A\n",
      " 74%|███████▎  | 367/499 [01:16<00:24,  5.32it/s]\u001b[A\n",
      " 74%|███████▎  | 368/499 [01:17<00:27,  4.85it/s]\u001b[A\n",
      " 74%|███████▍  | 369/499 [01:17<00:24,  5.38it/s]\u001b[A\n",
      " 74%|███████▍  | 370/499 [01:17<00:27,  4.73it/s]\u001b[A\n",
      " 74%|███████▍  | 371/499 [01:17<00:24,  5.29it/s]\u001b[A\n",
      " 75%|███████▍  | 372/499 [01:17<00:26,  4.72it/s]\u001b[A\n",
      " 75%|███████▍  | 373/499 [01:17<00:23,  5.28it/s]\u001b[A\n",
      " 75%|███████▍  | 374/499 [01:18<00:27,  4.59it/s]\u001b[A\n",
      " 75%|███████▌  | 375/499 [01:18<00:24,  5.15it/s]\u001b[A\n",
      " 75%|███████▌  | 376/499 [01:18<00:27,  4.44it/s]\u001b[A\n",
      " 76%|███████▌  | 377/499 [01:18<00:24,  5.03it/s]\u001b[A\n",
      " 76%|███████▌  | 378/499 [01:19<00:26,  4.52it/s]\u001b[A\n",
      " 76%|███████▌  | 379/499 [01:19<00:23,  5.02it/s]\u001b[A\n",
      " 76%|███████▌  | 380/499 [01:19<00:26,  4.43it/s]\u001b[A\n",
      " 76%|███████▋  | 381/499 [01:19<00:23,  5.01it/s]\u001b[A\n",
      " 77%|███████▋  | 382/499 [01:19<00:26,  4.44it/s]\u001b[A\n",
      " 77%|███████▋  | 383/499 [01:20<00:23,  5.00it/s]\u001b[A\n",
      " 77%|███████▋  | 384/499 [01:20<00:26,  4.31it/s]\u001b[A\n",
      " 77%|███████▋  | 385/499 [01:20<00:23,  4.87it/s]\u001b[A\n",
      " 77%|███████▋  | 386/499 [01:20<00:25,  4.35it/s]\u001b[A\n",
      " 78%|███████▊  | 387/499 [01:20<00:22,  4.92it/s]\u001b[A\n",
      " 78%|███████▊  | 388/499 [01:21<00:25,  4.34it/s]\u001b[A\n",
      " 78%|███████▊  | 389/499 [01:21<00:22,  4.88it/s]\u001b[A\n",
      " 78%|███████▊  | 390/499 [01:21<00:25,  4.32it/s]\u001b[A\n",
      " 78%|███████▊  | 391/499 [01:21<00:22,  4.83it/s]\u001b[A\n",
      " 79%|███████▊  | 392/499 [01:22<00:24,  4.29it/s]\u001b[A\n",
      " 79%|███████▉  | 393/499 [01:22<00:21,  4.83it/s]\u001b[A\n",
      " 79%|███████▉  | 394/499 [01:22<00:24,  4.31it/s]\u001b[A\n",
      " 79%|███████▉  | 395/499 [01:22<00:21,  4.87it/s]\u001b[A\n",
      " 79%|███████▉  | 396/499 [01:23<00:24,  4.17it/s]\u001b[A\n",
      " 80%|███████▉  | 397/499 [01:23<00:21,  4.73it/s]\u001b[A\n",
      " 80%|███████▉  | 398/499 [01:23<00:23,  4.33it/s]\u001b[A\n",
      " 80%|███████▉  | 399/499 [01:23<00:20,  4.88it/s]\u001b[A\n",
      " 80%|████████  | 400/499 [01:23<00:22,  4.31it/s]\u001b[A\n",
      " 80%|████████  | 401/499 [01:24<00:20,  4.85it/s]\u001b[A\n",
      " 81%|████████  | 402/499 [01:24<00:22,  4.33it/s]\u001b[A\n",
      " 81%|████████  | 403/499 [01:24<00:19,  4.90it/s]\u001b[A\n",
      " 81%|████████  | 404/499 [01:24<00:21,  4.37it/s]\u001b[A\n",
      " 81%|████████  | 405/499 [01:24<00:19,  4.91it/s]\u001b[A\n",
      " 81%|████████▏ | 406/499 [01:25<00:20,  4.43it/s]\u001b[A\n",
      " 82%|████████▏ | 407/499 [01:25<00:18,  4.98it/s]\u001b[A\n",
      " 82%|████████▏ | 408/499 [01:25<00:20,  4.41it/s]\u001b[A\n",
      " 82%|████████▏ | 409/499 [01:25<00:17,  5.00it/s]\u001b[A\n",
      " 82%|████████▏ | 410/499 [01:26<00:20,  4.43it/s]\u001b[A\n",
      " 82%|████████▏ | 411/499 [01:26<00:17,  4.99it/s]\u001b[A\n",
      " 83%|████████▎ | 412/499 [01:26<00:19,  4.45it/s]\u001b[A\n",
      " 83%|████████▎ | 413/499 [01:26<00:17,  5.03it/s]\u001b[A\n",
      " 83%|████████▎ | 414/499 [01:26<00:18,  4.50it/s]\u001b[A\n",
      " 83%|████████▎ | 415/499 [01:27<00:16,  5.07it/s]\u001b[A\n",
      " 83%|████████▎ | 416/499 [01:27<00:18,  4.55it/s]\u001b[A\n",
      " 84%|████████▎ | 417/499 [01:27<00:16,  5.12it/s]\u001b[A\n",
      " 84%|████████▍ | 418/499 [01:27<00:17,  4.55it/s]\u001b[A\n",
      " 84%|████████▍ | 419/499 [01:27<00:15,  5.09it/s]\u001b[A\n",
      " 84%|████████▍ | 420/499 [01:28<00:17,  4.54it/s]\u001b[A\n",
      " 84%|████████▍ | 421/499 [01:28<00:15,  5.09it/s]\u001b[A\n",
      " 85%|████████▍ | 422/499 [01:28<00:17,  4.53it/s]\u001b[A\n",
      " 85%|████████▍ | 423/499 [01:28<00:14,  5.08it/s]\u001b[A\n",
      " 85%|████████▍ | 424/499 [01:28<00:16,  4.54it/s]\u001b[A\n",
      " 85%|████████▌ | 425/499 [01:29<00:14,  5.07it/s]\u001b[A\n",
      " 85%|████████▌ | 426/499 [01:29<00:15,  4.56it/s]\u001b[A\n",
      " 86%|████████▌ | 427/499 [01:29<00:14,  5.10it/s]\u001b[A\n",
      " 86%|████████▌ | 428/499 [01:29<00:16,  4.19it/s]\u001b[A\n",
      " 86%|████████▌ | 429/499 [01:30<00:14,  4.75it/s]\u001b[A\n",
      " 86%|████████▌ | 430/499 [01:30<00:21,  3.27it/s]\u001b[A\n",
      " 86%|████████▋ | 431/499 [01:30<00:17,  3.91it/s]\u001b[A\n",
      " 87%|████████▋ | 432/499 [01:30<00:17,  3.80it/s]\u001b[A\n",
      " 87%|████████▋ | 433/499 [01:31<00:14,  4.43it/s]\u001b[A\n",
      " 87%|████████▋ | 434/499 [01:31<00:15,  4.14it/s]\u001b[A\n",
      " 87%|████████▋ | 435/499 [01:31<00:13,  4.66it/s]\u001b[A\n",
      " 87%|████████▋ | 436/499 [01:31<00:13,  4.54it/s]\u001b[A\n",
      " 88%|████████▊ | 437/499 [01:31<00:12,  5.09it/s]\u001b[A\n",
      " 88%|████████▊ | 438/499 [01:32<00:13,  4.62it/s]\u001b[A\n",
      " 88%|████████▊ | 439/499 [01:32<00:11,  5.15it/s]\u001b[A\n",
      " 88%|████████▊ | 440/499 [01:32<00:12,  4.67it/s]\u001b[A\n",
      " 88%|████████▊ | 441/499 [01:32<00:11,  5.10it/s]\u001b[A\n",
      " 89%|████████▊ | 442/499 [01:32<00:12,  4.71it/s]\u001b[A\n",
      " 89%|████████▉ | 443/499 [01:33<00:11,  5.06it/s]\u001b[A\n",
      " 89%|████████▉ | 444/499 [01:33<00:11,  4.76it/s]\u001b[A\n",
      " 89%|████████▉ | 445/499 [01:33<00:10,  5.26it/s]\u001b[A\n",
      " 89%|████████▉ | 446/499 [01:33<00:11,  4.68it/s]\u001b[A\n",
      " 90%|████████▉ | 447/499 [01:33<00:09,  5.20it/s]\u001b[A\n",
      " 90%|████████▉ | 448/499 [01:34<00:10,  4.72it/s]\u001b[A\n",
      " 90%|████████▉ | 449/499 [01:34<00:09,  5.23it/s]\u001b[A\n",
      " 90%|█████████ | 450/499 [01:34<00:10,  4.68it/s]\u001b[A\n",
      " 90%|█████████ | 451/499 [01:34<00:09,  5.18it/s]\u001b[A\n",
      " 91%|█████████ | 452/499 [01:35<00:10,  4.67it/s]\u001b[A\n",
      " 91%|█████████ | 453/499 [01:35<00:08,  5.16it/s]\u001b[A\n",
      " 91%|█████████ | 454/499 [01:35<00:09,  4.59it/s]\u001b[A\n",
      " 91%|█████████ | 455/499 [01:35<00:08,  5.05it/s]\u001b[A\n",
      " 91%|█████████▏| 456/499 [01:35<00:08,  4.80it/s]\u001b[A\n",
      " 92%|█████████▏| 457/499 [01:35<00:08,  5.23it/s]\u001b[A\n",
      " 92%|█████████▏| 458/499 [01:36<00:08,  4.80it/s]\u001b[A\n",
      " 92%|█████████▏| 459/499 [01:36<00:07,  5.30it/s]\u001b[A\n",
      " 92%|█████████▏| 460/499 [01:36<00:08,  4.71it/s]\u001b[A\n",
      " 92%|█████████▏| 461/499 [01:36<00:07,  5.19it/s]\u001b[A\n",
      " 93%|█████████▎| 462/499 [01:37<00:07,  4.86it/s]\u001b[A\n",
      " 93%|█████████▎| 463/499 [01:37<00:06,  5.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 464/499 [01:37<00:07,  4.94it/s]\u001b[A\n",
      " 93%|█████████▎| 465/499 [01:37<00:06,  5.44it/s]\u001b[A\n",
      " 93%|█████████▎| 466/499 [01:37<00:06,  4.86it/s]\u001b[A\n",
      " 94%|█████████▎| 467/499 [01:37<00:06,  5.23it/s]\u001b[A\n",
      " 94%|█████████▍| 468/499 [01:38<00:06,  4.85it/s]\u001b[A\n",
      " 94%|█████████▍| 469/499 [01:38<00:05,  5.35it/s]\u001b[A\n",
      " 94%|█████████▍| 470/499 [01:38<00:06,  4.81it/s]\u001b[A\n",
      " 94%|█████████▍| 471/499 [01:38<00:05,  5.28it/s]\u001b[A\n",
      " 95%|█████████▍| 472/499 [01:39<00:05,  4.68it/s]\u001b[A\n",
      " 95%|█████████▍| 473/499 [01:39<00:05,  4.78it/s]\u001b[A\n",
      " 95%|█████████▍| 474/499 [01:39<00:05,  4.96it/s]\u001b[A\n",
      " 95%|█████████▌| 475/499 [01:39<00:04,  4.94it/s]\u001b[A\n",
      " 95%|█████████▌| 476/499 [01:39<00:04,  5.01it/s]\u001b[A\n",
      " 96%|█████████▌| 477/499 [01:40<00:04,  4.81it/s]\u001b[A\n",
      " 96%|█████████▌| 478/499 [01:40<00:04,  5.11it/s]\u001b[A\n",
      " 96%|█████████▌| 479/499 [01:40<00:04,  4.70it/s]\u001b[A\n",
      " 96%|█████████▌| 480/499 [01:40<00:03,  5.07it/s]\u001b[A\n",
      " 96%|█████████▋| 481/499 [01:40<00:03,  4.66it/s]\u001b[A\n",
      " 97%|█████████▋| 482/499 [01:40<00:03,  5.18it/s]\u001b[A\n",
      " 97%|█████████▋| 483/499 [01:41<00:03,  4.63it/s]\u001b[A\n",
      " 97%|█████████▋| 484/499 [01:41<00:02,  5.15it/s]\u001b[A\n",
      " 97%|█████████▋| 485/499 [01:41<00:03,  4.60it/s]\u001b[A\n",
      " 97%|█████████▋| 486/499 [01:41<00:02,  5.07it/s]\u001b[A\n",
      " 98%|█████████▊| 487/499 [01:42<00:02,  4.54it/s]\u001b[A\n",
      " 98%|█████████▊| 488/499 [01:42<00:02,  5.02it/s]\u001b[A\n",
      " 98%|█████████▊| 489/499 [01:42<00:02,  4.61it/s]\u001b[A\n",
      " 98%|█████████▊| 490/499 [01:42<00:01,  5.03it/s]\u001b[A\n",
      " 98%|█████████▊| 491/499 [01:42<00:01,  4.80it/s]\u001b[A\n",
      " 99%|█████████▊| 492/499 [01:43<00:01,  5.34it/s]\u001b[A\n",
      " 99%|█████████▉| 493/499 [01:43<00:01,  4.69it/s]\u001b[A\n",
      " 99%|█████████▉| 494/499 [01:43<00:00,  5.20it/s]\u001b[A\n",
      " 99%|█████████▉| 495/499 [01:43<00:00,  4.72it/s]\u001b[A\n",
      " 99%|█████████▉| 496/499 [01:43<00:00,  5.24it/s]\u001b[A\n",
      "100%|█████████▉| 497/499 [01:44<00:00,  4.73it/s]\u001b[A\n",
      "100%|██████████| 499/499 [01:44<00:00,  4.76it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "valid_preds=validation_fn(model,valid_loader,is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights=get_weights(valid_preds,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.25704842, 1.36293571, 1.00009491])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.08458763e+00, 4.53690968e-02, 4.31261982e-02],\n",
       "       [2.16295168e+00, 3.40681533e-02, 1.66956776e-02],\n",
       "       [2.25369632e+00, 1.21261773e-03, 5.95427865e-04],\n",
       "       ...,\n",
       "       [2.25385843e+00, 3.07184703e-04, 1.18809666e-03],\n",
       "       [2.21216485e+00, 1.56658540e-02, 8.39254654e-03],\n",
       "       [2.19449009e+00, 3.40683513e-02, 2.72079814e-03]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=weights*preds\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label']=np.argmax(preds,axis=1)+1\n",
    "test[['link','current_slice_id','future_slice_id','label']].to_csv(nn_result_save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    171925\n",
      "2      3026\n",
      "3      1106\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(prob_save_path,'wb') as f:\n",
    "    pickle.dump(preds,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "524.8px",
    "left": "27px",
    "top": "110px",
    "width": "219.45px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
